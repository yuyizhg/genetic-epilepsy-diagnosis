{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!ls \"/content/drive/MyDrive/Stanford/CS229/Final Project/llama+udmp-densityclustering_synthetic cases\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdpRUqQyqZbm",
        "outputId": "79a4f769-8d9e-409e-f9f3-d159eb2ff22e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "'3-4-UMAP based GNN classifier.py'\n",
            " synthetic_patients_internal_test_cohort.csv\n",
            " synthetic_patients_internal_test_cohort.jsonl\n",
            " synthetic_patients_training_cohort.csv\n",
            " synthetic_patients_training_cohort.jsonl\n",
            "'test-cohort-3-4-UMAP-GNN validation.py'\n",
            "'test-cohort-llama-density-clusters-case-aggregated-vectors (1).gsheet'\n",
            " test-cohort-llama-density-clusters-case-aggregated-vectors.csv\n",
            " test-cohort-llama-density-clusters-case-aggregated-vectors.gsheet\n",
            " test-cohort-llama-density-clusters-case-aggregated-vectors.jsonl\n",
            " test-cohort-llama-density-UMAP-GNN-Validation-output.log\n",
            " XGBoost.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1 Set up helpers And Load Data"
      ],
      "metadata": {
        "id": "o-zz5Pumyyxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import lil_matrix, csr_matrix, hstack\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, top_k_accuracy_score\n",
        "\n",
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "EGZ7GvOoxwYp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to your new density-clustering datasets\n",
        "train_path = Path(\"/content/drive/MyDrive/Stanford/CS229/Final Project/llama+udmp-densityclustering_synthetic cases/synthetic_patients_training_cohort.jsonl\")\n",
        "test_path  = Path(\"/content/drive/MyDrive/Stanford/CS229/Final Project/llama+udmp-densityclustering_synthetic cases/synthetic_patients_internal_test_cohort.jsonl\")\n",
        "\n",
        "def load_jsonl(path: Path) -> pd.DataFrame:\n",
        "    records = []\n",
        "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            records.append(json.loads(line))\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "df_train = load_jsonl(train_path)\n",
        "df_test  = load_jsonl(test_path)\n",
        "\n",
        "print(\"Train shape:\", df_train.shape)\n",
        "print(\"Test shape:\", df_test.shape)\n",
        "df_train.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "PHYmKbnUrEvG",
        "outputId": "b2c72a0a-ab5b-429f-8c5a-0d6d5ae3efbc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (132800, 6)\n",
            "Test shape: (34860, 6)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        patient_id  \\\n",
              "0  2,4-DIENOYL-CoA REDUCTASE DEFICIENCY; DECRD_P20   \n",
              "\n",
              "                                     diagnosis  symptom_completeness_pct  \\\n",
              "0  2,4-DIENOYL-CoA REDUCTASE DEFICIENCY; DECRD                      60.0   \n",
              "\n",
              "                                   symptoms_clusters  \\\n",
              "0  [4529, 852, 2001, 68, 4530, 308, 1187, 1087, 2...   \n",
              "\n",
              "                               symptoms_vectors_100d      cohort_type  \n",
              "0  [[-0.27515015, 0.61182046, -1.103897, -1.42158...  training_cohort  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4323ce8c-3fdf-42ed-88d4-983696c2f986\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patient_id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>symptom_completeness_pct</th>\n",
              "      <th>symptoms_clusters</th>\n",
              "      <th>symptoms_vectors_100d</th>\n",
              "      <th>cohort_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2,4-DIENOYL-CoA REDUCTASE DEFICIENCY; DECRD_P20</td>\n",
              "      <td>2,4-DIENOYL-CoA REDUCTASE DEFICIENCY; DECRD</td>\n",
              "      <td>60.0</td>\n",
              "      <td>[4529, 852, 2001, 68, 4530, 308, 1187, 1087, 2...</td>\n",
              "      <td>[[-0.27515015, 0.61182046, -1.103897, -1.42158...</td>\n",
              "      <td>training_cohort</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4323ce8c-3fdf-42ed-88d4-983696c2f986')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4323ce8c-3fdf-42ed-88d4-983696c2f986 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4323ce8c-3fdf-42ed-88d4-983696c2f986');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Build a cluster vocabulary (from training set only)"
      ],
      "metadata": {
        "id": "A_W5X7R9zB9u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "We map cluster IDs → column indices so we get a fixed-length multi-hot vector for each patient."
      ],
      "metadata": {
        "id": "4zp2H2dvyalk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect all unique cluster IDs from training data\n",
        "cluster_set = set()\n",
        "for clusters in df_train[\"symptoms_clusters\"]:\n",
        "    cluster_set.update(clusters)\n",
        "\n",
        "cluster_list = sorted(cluster_set)\n",
        "cluster2idx = {cid: i for i, cid in enumerate(cluster_list)}\n",
        "\n",
        "n_clusters = len(cluster2idx)\n",
        "print(\"Number of unique clusters (train):\", n_clusters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzxCR5dWyW_j",
        "outputId": "3d49689f-1cb3-45fc-c8f6-71d520275b50"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique clusters (train): 5362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save this file for reproducibility\n",
        "with open(\"density_cluster_vocab.json\", \"w\") as f:\n",
        "    json.dump({\"cluster_list\": cluster_list}, f)"
      ],
      "metadata": {
        "id": "XUFyhaqRzOgq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Feature Builder\n",
        "We’ll construct:\n",
        "\n",
        "\n",
        "*   X_clusters : multi-hot over cluster IDs (sparse)\n",
        "*   X_embed    : mean of symptoms_vectors_100d per patient (dense 100-d)\n",
        "*   X_extra    : symptom_completeness_pct (scaled to 0–1)\n",
        "\n",
        "Then we hstack them into a single sparse matrix for XGBoost."
      ],
      "metadata": {
        "id": "qFr8viuwzYqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_features(df: pd.DataFrame, cluster2idx: dict) -> csr_matrix:\n",
        "    n_samples = len(df)\n",
        "    n_clusters = len(cluster2idx)\n",
        "\n",
        "    # multi-hot cluster features (sparse)\n",
        "    X_clusters = lil_matrix((n_samples, n_clusters), dtype=np.float32)\n",
        "\n",
        "    # infer embedding dim from first row\n",
        "    first_vecs = df.iloc[0][\"symptoms_vectors_100d\"]\n",
        "    embedding_dim = len(first_vecs[0])\n",
        "    X_embed = np.zeros((n_samples, embedding_dim), dtype=np.float32)\n",
        "\n",
        "    # extra scalar feature: completeness\n",
        "    X_compl = np.zeros((n_samples, 1), dtype=np.float32)\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        # multi-hot over clusters\n",
        "        for cid in row[\"symptoms_clusters\"]:\n",
        "            j = cluster2idx.get(cid)\n",
        "            if j is not None:\n",
        "                X_clusters[i, j] = 1.0\n",
        "\n",
        "        # mean embedding over all symptoms for this patient\n",
        "        vecs = np.array(row[\"symptoms_vectors_100d\"], dtype=np.float32)  # (num_symptoms, 100)\n",
        "        X_embed[i] = vecs.mean(axis=0)\n",
        "\n",
        "        # completeness in [0,1]\n",
        "        X_compl[i, 0] = float(row[\"symptom_completeness_pct\"]) / 100.0\n",
        "\n",
        "    # Convert to csr and hstack dense features as sparse\n",
        "    X_clusters = X_clusters.tocsr()\n",
        "    X_dense = np.hstack([X_embed, X_compl])  # shape: (n_samples, 100 + 1)\n",
        "    X_dense_sparse = csr_matrix(X_dense)\n",
        "\n",
        "    X = hstack([X_clusters, X_dense_sparse], format=\"csr\")\n",
        "    return X"
      ],
      "metadata": {
        "id": "cfEx1YaczXwE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build X_train and X_test"
      ],
      "metadata": {
        "id": "OEo4CW7U0B2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = build_features(df_train, cluster2idx)\n",
        "X_test  = build_features(df_test, cluster2idx)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8gVvgdrzXtL",
        "outputId": "35818941-58d6-47b9-abfb-b03efeb78227"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (132800, 5463)\n",
            "X_test shape: (34860, 5463)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Encode labels"
      ],
      "metadata": {
        "id": "mtRMLJbj0Vht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(df_train[\"diagnosis\"])\n",
        "y_test  = le.transform(df_test[\"diagnosis\"])\n",
        "\n",
        "num_classes = len(le.classes_)\n",
        "print(\"Number of classes:\", num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2lJ5B_ezXqj",
        "outputId": "0f9e2ccb-8a7d-4137-a040-e6c3e18d082d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 1660\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Train XGBoost"
      ],
      "metadata": {
        "id": "TswdMrjb04qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "print(\"XGBoost version:\", xgb.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpS4EgYV2YFw",
        "outputId": "6ac9c1c0-2b33-4ce7-d323-ee5a96ae1251"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost version: 3.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "d-i8AOCO24f4",
        "outputId": "0b1a8362-4111-493d-9294-ca2c8ffe3dca"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "TrainingCheckPoint.__init__() got an unexpected keyword argument 'iterations'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1262112241.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# 5.4 Set up checkpoint callback (no validation / early stopping yet)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# ---------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m checkpoint_cb = xgb.callback.TrainingCheckPoint(\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mdirectory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"xgb_density\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: TrainingCheckPoint.__init__() got an unexpected keyword argument 'iterations'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, glob, json, pickle\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "from xgboost import callback\n",
        "\n",
        "# ========= CONFIG =========\n",
        "SAVE_DIR = Path(\"/content/drive/MyDrive/Stanford/CS229/Final Project/llama+udmp-densityclustering_synthetic cases/xgb_checkpoints\")\n",
        "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "NUM_CLASS = len(le.classes_)     # from your LabelEncoder on y_train\n",
        "N_BOOST_ROUNDS = 1000            # cap on total trees\n",
        "EARLY_STOPPING_ROUNDS = 100      # stop if no improvement\n",
        "CHECKPOINT_EVERY = 250           # save every N rounds\n",
        "RANDOM_STATE = 42\n",
        "N_SPLITS = 5\n",
        "# ==========================\n",
        "\n",
        "# ---- Version-agnostic periodic saver ----\n",
        "class PeriodicSaver(callback.TrainingCallback):\n",
        "    \"\"\"Save booster every `every` rounds to SAVE_DIR / f'{name}_{iter:04d}.json'.\"\"\"\n",
        "    def __init__(self, save_dir: Path, name: str, every: int):\n",
        "        self.save_dir = Path(save_dir)\n",
        "        self.name = name\n",
        "        self.every = int(every)\n",
        "\n",
        "    def after_iteration(self, model, epoch: int, evals_log) -> bool:\n",
        "        it = epoch + 1\n",
        "        if it % self.every == 0:\n",
        "            path = self.save_dir / f\"{self.name}_{it:04d}.json\"\n",
        "            model.save_model(str(path))\n",
        "            print(f\"[checkpoint] saved {path}\")\n",
        "        return False  # continue training\n",
        "\n",
        "def latest_checkpoint_for_fold(save_dir: Path, fold: int):\n",
        "    \"\"\"Return path to latest checkpoint (json) for this fold, or None.\"\"\"\n",
        "    pattern = str(save_dir / f\"xgb_fold{fold}_*.json\")\n",
        "    candidates = glob.glob(pattern)\n",
        "    if not candidates:\n",
        "        return None\n",
        "    best, best_iter = None, -1\n",
        "    rx = re.compile(rf\"xgb_fold{fold}_(\\d+)\\.json$\")\n",
        "    for p in candidates:\n",
        "        m = rx.search(os.path.basename(p))\n",
        "        if m:\n",
        "            it = int(m.group(1))\n",
        "            if it > best_iter:\n",
        "                best_iter, best = it, p\n",
        "    return best\n",
        "\n",
        "# Adjust folds if the rarest class is too small\n",
        "min_per_class = min(Counter(y_train_enc).values())\n",
        "actual_splits = min(N_SPLITS, max(2, min_per_class))\n",
        "print(f\"Using {actual_splits}-fold CV (min per class = {min_per_class})\")\n",
        "\n",
        "kf = StratifiedKFold(n_splits=actual_splits, shuffle=True, random_state=RANDOM_STATE)\n",
        "fold_accs = []\n",
        "\n",
        "# Common XGBoost params\n",
        "params = {\n",
        "    \"objective\": \"multi:softprob\",\n",
        "    \"num_class\": NUM_CLASS,\n",
        "    \"eval_metric\": \"mlogloss\",\n",
        "    \"max_depth\": 4,\n",
        "    \"learning_rate\": 0.1,\n",
        "    \"subsample\": 0.9,\n",
        "    \"colsample_bytree\": 0.9,\n",
        "    \"reg_lambda\": 1.0,\n",
        "    \"tree_method\": \"hist\",\n",
        "    \"device\": \"cuda\",\n",
        "    \"seed\": RANDOM_STATE,\n",
        "}\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train_enc), 1):\n",
        "    print(f\"\\n===== Fold {fold} =====\")\n",
        "    X_tr, X_va = X_train[train_idx], X_train[val_idx]\n",
        "    y_tr, y_va = y_train_enc[train_idx], y_train_enc[val_idx]\n",
        "\n",
        "    dtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
        "    dvalid = xgb.DMatrix(X_va, label=y_va)\n",
        "    evals = [(dtrain, \"train\"), (dvalid, \"valid\")]\n",
        "\n",
        "    resume_path = latest_checkpoint_for_fold(SAVE_DIR, fold)\n",
        "    if resume_path:\n",
        "        print(f\"➡️  Resuming from checkpoint: {resume_path}\")\n",
        "    else:\n",
        "        print(\"➡️  No checkpoint found; starting fresh.\")\n",
        "\n",
        "    saver_cb = PeriodicSaver(SAVE_DIR, name=f\"xgb_fold{fold}\", every=CHECKPOINT_EVERY)\n",
        "\n",
        "    # Train (resume if checkpoint exists)\n",
        "    booster = xgb.train(\n",
        "        params=params,\n",
        "        dtrain=dtrain,\n",
        "        num_boost_round=N_BOOST_ROUNDS,\n",
        "        evals=evals,\n",
        "        early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
        "        callbacks=[saver_cb],\n",
        "        xgb_model=resume_path if resume_path else None,\n",
        "        verbose_eval=True\n",
        "    )\n",
        "\n",
        "    # Save final model (JSON, portable)\n",
        "    final_json = SAVE_DIR / f\"xgb_fold{fold}_final.json\"\n",
        "    booster.save_model(str(final_json))\n",
        "    print(f\"✅ Saved final model: {final_json}\")\n",
        "\n",
        "    # Predict on this fold's holdout and score\n",
        "    y_prob = booster.predict(dvalid, iteration_range=(0, booster.best_iteration + 1) if booster.best_iteration is not None else None)\n",
        "    y_pred = np.argmax(y_prob, axis=1)\n",
        "    acc = accuracy_score(y_va, y_pred)\n",
        "    fold_accs.append(acc)\n",
        "    print(f\"Fold {fold} accuracy: {acc:.4f}\")\n",
        "    if booster.best_iteration is not None:\n",
        "        print(f\"Best iteration (early stop): {booster.best_iteration}\")\n",
        "\n",
        "mean_acc, std_acc = np.mean(fold_accs), np.std(fold_accs)\n",
        "print(f\"\\nMean CV accuracy: {mean_acc:.4f} ± {std_acc:.4f}\")\n",
        "print(f\"All checkpoints & final models in: {SAVE_DIR}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hSAXgCE5zuF",
        "outputId": "8a80624e-9fdc-411c-904c-fa0e0cb14d63"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 5-fold CV (min per class = 80)\n",
            "\n",
            "===== Fold 1 =====\n",
            "➡️  No checkpoint found; starting fresh.\n",
            "[0]\ttrain-mlogloss:5.86840\tvalid-mlogloss:5.96094\n",
            "[1]\ttrain-mlogloss:4.41167\tvalid-mlogloss:4.59711\n",
            "[2]\ttrain-mlogloss:3.15195\tvalid-mlogloss:3.42456\n",
            "[3]\ttrain-mlogloss:2.59658\tvalid-mlogloss:2.89889\n",
            "[4]\ttrain-mlogloss:2.23119\tvalid-mlogloss:2.55833\n",
            "[5]\ttrain-mlogloss:1.95089\tvalid-mlogloss:2.29762\n",
            "[6]\ttrain-mlogloss:1.72572\tvalid-mlogloss:2.08731\n",
            "[7]\ttrain-mlogloss:1.53929\tvalid-mlogloss:1.91219\n",
            "[8]\ttrain-mlogloss:1.38104\tvalid-mlogloss:1.76249\n",
            "[9]\ttrain-mlogloss:1.24494\tvalid-mlogloss:1.63267\n",
            "[10]\ttrain-mlogloss:1.12656\tvalid-mlogloss:1.51955\n",
            "[11]\ttrain-mlogloss:1.02236\tvalid-mlogloss:1.41806\n",
            "[12]\ttrain-mlogloss:0.93034\tvalid-mlogloss:1.32792\n",
            "[13]\ttrain-mlogloss:0.84830\tvalid-mlogloss:1.24639\n",
            "[14]\ttrain-mlogloss:0.77484\tvalid-mlogloss:1.17253\n",
            "[15]\ttrain-mlogloss:0.70880\tvalid-mlogloss:1.10521\n",
            "[16]\ttrain-mlogloss:0.64935\tvalid-mlogloss:1.04387\n",
            "[17]\ttrain-mlogloss:0.59559\tvalid-mlogloss:0.98700\n",
            "[18]\ttrain-mlogloss:0.54678\tvalid-mlogloss:0.93458\n",
            "[19]\ttrain-mlogloss:0.50246\tvalid-mlogloss:0.88603\n",
            "[20]\ttrain-mlogloss:0.46210\tvalid-mlogloss:0.84111\n",
            "[21]\ttrain-mlogloss:0.42533\tvalid-mlogloss:0.79938\n",
            "[22]\ttrain-mlogloss:0.39183\tvalid-mlogloss:0.76046\n",
            "[23]\ttrain-mlogloss:0.36121\tvalid-mlogloss:0.72432\n",
            "[24]\ttrain-mlogloss:0.33328\tvalid-mlogloss:0.69071\n",
            "[25]\ttrain-mlogloss:0.30773\tvalid-mlogloss:0.65932\n",
            "[26]\ttrain-mlogloss:0.28432\tvalid-mlogloss:0.62990\n",
            "[27]\ttrain-mlogloss:0.26294\tvalid-mlogloss:0.60224\n",
            "[28]\ttrain-mlogloss:0.24333\tvalid-mlogloss:0.57654\n",
            "[29]\ttrain-mlogloss:0.22535\tvalid-mlogloss:0.55243\n",
            "[30]\ttrain-mlogloss:0.20886\tvalid-mlogloss:0.52971\n",
            "[31]\ttrain-mlogloss:0.19375\tvalid-mlogloss:0.50833\n",
            "[32]\ttrain-mlogloss:0.17986\tvalid-mlogloss:0.48813\n",
            "[33]\ttrain-mlogloss:0.16713\tvalid-mlogloss:0.46912\n",
            "[34]\ttrain-mlogloss:0.15541\tvalid-mlogloss:0.45130\n",
            "[35]\ttrain-mlogloss:0.14466\tvalid-mlogloss:0.43452\n",
            "[36]\ttrain-mlogloss:0.13476\tvalid-mlogloss:0.41864\n",
            "[37]\ttrain-mlogloss:0.12564\tvalid-mlogloss:0.40351\n",
            "[38]\ttrain-mlogloss:0.11723\tvalid-mlogloss:0.38939\n",
            "[39]\ttrain-mlogloss:0.10948\tvalid-mlogloss:0.37609\n",
            "[40]\ttrain-mlogloss:0.10234\tvalid-mlogloss:0.36352\n",
            "[41]\ttrain-mlogloss:0.09576\tvalid-mlogloss:0.35159\n",
            "[42]\ttrain-mlogloss:0.08969\tvalid-mlogloss:0.34034\n",
            "[43]\ttrain-mlogloss:0.08409\tvalid-mlogloss:0.32960\n",
            "[44]\ttrain-mlogloss:0.07895\tvalid-mlogloss:0.31943\n",
            "[45]\ttrain-mlogloss:0.07418\tvalid-mlogloss:0.30983\n",
            "[46]\ttrain-mlogloss:0.06979\tvalid-mlogloss:0.30077\n",
            "[47]\ttrain-mlogloss:0.06571\tvalid-mlogloss:0.29225\n",
            "[48]\ttrain-mlogloss:0.06194\tvalid-mlogloss:0.28397\n",
            "[49]\ttrain-mlogloss:0.05845\tvalid-mlogloss:0.27615\n",
            "[50]\ttrain-mlogloss:0.05523\tvalid-mlogloss:0.26874\n",
            "[51]\ttrain-mlogloss:0.05224\tvalid-mlogloss:0.26169\n",
            "[52]\ttrain-mlogloss:0.04949\tvalid-mlogloss:0.25501\n",
            "[53]\ttrain-mlogloss:0.04694\tvalid-mlogloss:0.24866\n",
            "[54]\ttrain-mlogloss:0.04457\tvalid-mlogloss:0.24272\n",
            "[55]\ttrain-mlogloss:0.04236\tvalid-mlogloss:0.23704\n",
            "[56]\ttrain-mlogloss:0.04032\tvalid-mlogloss:0.23159\n",
            "[57]\ttrain-mlogloss:0.03845\tvalid-mlogloss:0.22647\n",
            "[58]\ttrain-mlogloss:0.03670\tvalid-mlogloss:0.22165\n",
            "[59]\ttrain-mlogloss:0.03506\tvalid-mlogloss:0.21705\n",
            "[60]\ttrain-mlogloss:0.03353\tvalid-mlogloss:0.21262\n",
            "[61]\ttrain-mlogloss:0.03211\tvalid-mlogloss:0.20837\n",
            "[62]\ttrain-mlogloss:0.03076\tvalid-mlogloss:0.20435\n",
            "[63]\ttrain-mlogloss:0.02952\tvalid-mlogloss:0.20050\n",
            "[64]\ttrain-mlogloss:0.02835\tvalid-mlogloss:0.19683\n",
            "[65]\ttrain-mlogloss:0.02725\tvalid-mlogloss:0.19339\n",
            "[66]\ttrain-mlogloss:0.02622\tvalid-mlogloss:0.18999\n",
            "[67]\ttrain-mlogloss:0.02525\tvalid-mlogloss:0.18679\n",
            "[68]\ttrain-mlogloss:0.02435\tvalid-mlogloss:0.18368\n",
            "[69]\ttrain-mlogloss:0.02349\tvalid-mlogloss:0.18067\n",
            "[70]\ttrain-mlogloss:0.02268\tvalid-mlogloss:0.17788\n",
            "[71]\ttrain-mlogloss:0.02193\tvalid-mlogloss:0.17512\n",
            "[72]\ttrain-mlogloss:0.02121\tvalid-mlogloss:0.17248\n",
            "[73]\ttrain-mlogloss:0.02054\tvalid-mlogloss:0.16996\n",
            "[74]\ttrain-mlogloss:0.01991\tvalid-mlogloss:0.16757\n",
            "[75]\ttrain-mlogloss:0.01929\tvalid-mlogloss:0.16526\n",
            "[76]\ttrain-mlogloss:0.01873\tvalid-mlogloss:0.16310\n",
            "[77]\ttrain-mlogloss:0.01818\tvalid-mlogloss:0.16103\n",
            "[78]\ttrain-mlogloss:0.01768\tvalid-mlogloss:0.15904\n",
            "[79]\ttrain-mlogloss:0.01720\tvalid-mlogloss:0.15716\n",
            "[80]\ttrain-mlogloss:0.01675\tvalid-mlogloss:0.15535\n",
            "[81]\ttrain-mlogloss:0.01632\tvalid-mlogloss:0.15369\n",
            "[82]\ttrain-mlogloss:0.01592\tvalid-mlogloss:0.15205\n",
            "[83]\ttrain-mlogloss:0.01554\tvalid-mlogloss:0.15052\n",
            "[84]\ttrain-mlogloss:0.01518\tvalid-mlogloss:0.14912\n",
            "[85]\ttrain-mlogloss:0.01485\tvalid-mlogloss:0.14769\n",
            "[86]\ttrain-mlogloss:0.01453\tvalid-mlogloss:0.14638\n",
            "[87]\ttrain-mlogloss:0.01423\tvalid-mlogloss:0.14511\n",
            "[88]\ttrain-mlogloss:0.01395\tvalid-mlogloss:0.14396\n",
            "[89]\ttrain-mlogloss:0.01369\tvalid-mlogloss:0.14285\n",
            "[90]\ttrain-mlogloss:0.01344\tvalid-mlogloss:0.14184\n",
            "[91]\ttrain-mlogloss:0.01320\tvalid-mlogloss:0.14088\n",
            "[92]\ttrain-mlogloss:0.01297\tvalid-mlogloss:0.13993\n",
            "[93]\ttrain-mlogloss:0.01276\tvalid-mlogloss:0.13904\n",
            "[94]\ttrain-mlogloss:0.01257\tvalid-mlogloss:0.13822\n",
            "[95]\ttrain-mlogloss:0.01238\tvalid-mlogloss:0.13743\n",
            "[96]\ttrain-mlogloss:0.01221\tvalid-mlogloss:0.13673\n",
            "[97]\ttrain-mlogloss:0.01205\tvalid-mlogloss:0.13608\n",
            "[98]\ttrain-mlogloss:0.01189\tvalid-mlogloss:0.13547\n",
            "[99]\ttrain-mlogloss:0.01176\tvalid-mlogloss:0.13488\n",
            "[100]\ttrain-mlogloss:0.01162\tvalid-mlogloss:0.13434\n",
            "[101]\ttrain-mlogloss:0.01150\tvalid-mlogloss:0.13384\n",
            "[102]\ttrain-mlogloss:0.01138\tvalid-mlogloss:0.13338\n",
            "[103]\ttrain-mlogloss:0.01127\tvalid-mlogloss:0.13298\n",
            "[104]\ttrain-mlogloss:0.01117\tvalid-mlogloss:0.13259\n",
            "[105]\ttrain-mlogloss:0.01107\tvalid-mlogloss:0.13221\n",
            "[106]\ttrain-mlogloss:0.01099\tvalid-mlogloss:0.13185\n",
            "[107]\ttrain-mlogloss:0.01090\tvalid-mlogloss:0.13151\n",
            "[108]\ttrain-mlogloss:0.01082\tvalid-mlogloss:0.13120\n",
            "[109]\ttrain-mlogloss:0.01075\tvalid-mlogloss:0.13094\n",
            "[110]\ttrain-mlogloss:0.01068\tvalid-mlogloss:0.13068\n",
            "[111]\ttrain-mlogloss:0.01061\tvalid-mlogloss:0.13045\n",
            "[112]\ttrain-mlogloss:0.01055\tvalid-mlogloss:0.13025\n",
            "[113]\ttrain-mlogloss:0.01049\tvalid-mlogloss:0.13008\n",
            "[114]\ttrain-mlogloss:0.01043\tvalid-mlogloss:0.12989\n",
            "[115]\ttrain-mlogloss:0.01038\tvalid-mlogloss:0.12971\n",
            "[116]\ttrain-mlogloss:0.01033\tvalid-mlogloss:0.12952\n",
            "[117]\ttrain-mlogloss:0.01028\tvalid-mlogloss:0.12937\n",
            "[118]\ttrain-mlogloss:0.01024\tvalid-mlogloss:0.12922\n",
            "[119]\ttrain-mlogloss:0.01019\tvalid-mlogloss:0.12906\n",
            "[120]\ttrain-mlogloss:0.01015\tvalid-mlogloss:0.12891\n",
            "[121]\ttrain-mlogloss:0.01011\tvalid-mlogloss:0.12878\n",
            "[122]\ttrain-mlogloss:0.01007\tvalid-mlogloss:0.12869\n",
            "[123]\ttrain-mlogloss:0.01004\tvalid-mlogloss:0.12857\n",
            "[124]\ttrain-mlogloss:0.01000\tvalid-mlogloss:0.12851\n",
            "[125]\ttrain-mlogloss:0.00997\tvalid-mlogloss:0.12845\n",
            "[126]\ttrain-mlogloss:0.00994\tvalid-mlogloss:0.12836\n",
            "[127]\ttrain-mlogloss:0.00991\tvalid-mlogloss:0.12827\n",
            "[128]\ttrain-mlogloss:0.00988\tvalid-mlogloss:0.12818\n",
            "[129]\ttrain-mlogloss:0.00985\tvalid-mlogloss:0.12808\n",
            "[130]\ttrain-mlogloss:0.00982\tvalid-mlogloss:0.12801\n",
            "[131]\ttrain-mlogloss:0.00980\tvalid-mlogloss:0.12793\n",
            "[132]\ttrain-mlogloss:0.00977\tvalid-mlogloss:0.12789\n",
            "[133]\ttrain-mlogloss:0.00975\tvalid-mlogloss:0.12784\n",
            "[134]\ttrain-mlogloss:0.00972\tvalid-mlogloss:0.12780\n",
            "[135]\ttrain-mlogloss:0.00970\tvalid-mlogloss:0.12775\n",
            "[136]\ttrain-mlogloss:0.00968\tvalid-mlogloss:0.12772\n",
            "[137]\ttrain-mlogloss:0.00966\tvalid-mlogloss:0.12768\n",
            "[138]\ttrain-mlogloss:0.00964\tvalid-mlogloss:0.12765\n",
            "[139]\ttrain-mlogloss:0.00962\tvalid-mlogloss:0.12761\n",
            "[140]\ttrain-mlogloss:0.00960\tvalid-mlogloss:0.12760\n",
            "[141]\ttrain-mlogloss:0.00958\tvalid-mlogloss:0.12757\n",
            "[142]\ttrain-mlogloss:0.00957\tvalid-mlogloss:0.12754\n",
            "[143]\ttrain-mlogloss:0.00955\tvalid-mlogloss:0.12748\n",
            "[144]\ttrain-mlogloss:0.00953\tvalid-mlogloss:0.12746\n",
            "[145]\ttrain-mlogloss:0.00951\tvalid-mlogloss:0.12745\n",
            "[146]\ttrain-mlogloss:0.00950\tvalid-mlogloss:0.12743\n",
            "[147]\ttrain-mlogloss:0.00948\tvalid-mlogloss:0.12741\n",
            "[148]\ttrain-mlogloss:0.00947\tvalid-mlogloss:0.12740\n",
            "[149]\ttrain-mlogloss:0.00945\tvalid-mlogloss:0.12738\n",
            "[150]\ttrain-mlogloss:0.00944\tvalid-mlogloss:0.12737\n",
            "[151]\ttrain-mlogloss:0.00943\tvalid-mlogloss:0.12735\n",
            "[152]\ttrain-mlogloss:0.00941\tvalid-mlogloss:0.12731\n",
            "[153]\ttrain-mlogloss:0.00940\tvalid-mlogloss:0.12728\n",
            "[154]\ttrain-mlogloss:0.00939\tvalid-mlogloss:0.12728\n",
            "[155]\ttrain-mlogloss:0.00938\tvalid-mlogloss:0.12726\n",
            "[156]\ttrain-mlogloss:0.00936\tvalid-mlogloss:0.12725\n",
            "[157]\ttrain-mlogloss:0.00935\tvalid-mlogloss:0.12725\n",
            "[158]\ttrain-mlogloss:0.00934\tvalid-mlogloss:0.12725\n",
            "[159]\ttrain-mlogloss:0.00933\tvalid-mlogloss:0.12724\n",
            "[160]\ttrain-mlogloss:0.00932\tvalid-mlogloss:0.12722\n",
            "[161]\ttrain-mlogloss:0.00931\tvalid-mlogloss:0.12720\n",
            "[162]\ttrain-mlogloss:0.00930\tvalid-mlogloss:0.12719\n",
            "[163]\ttrain-mlogloss:0.00929\tvalid-mlogloss:0.12719\n",
            "[164]\ttrain-mlogloss:0.00928\tvalid-mlogloss:0.12716\n",
            "[165]\ttrain-mlogloss:0.00927\tvalid-mlogloss:0.12714\n",
            "[166]\ttrain-mlogloss:0.00926\tvalid-mlogloss:0.12713\n",
            "[167]\ttrain-mlogloss:0.00925\tvalid-mlogloss:0.12714\n",
            "[168]\ttrain-mlogloss:0.00924\tvalid-mlogloss:0.12715\n",
            "[169]\ttrain-mlogloss:0.00923\tvalid-mlogloss:0.12715\n",
            "[170]\ttrain-mlogloss:0.00922\tvalid-mlogloss:0.12715\n",
            "[171]\ttrain-mlogloss:0.00921\tvalid-mlogloss:0.12716\n",
            "[172]\ttrain-mlogloss:0.00921\tvalid-mlogloss:0.12716\n",
            "[173]\ttrain-mlogloss:0.00920\tvalid-mlogloss:0.12715\n",
            "[174]\ttrain-mlogloss:0.00919\tvalid-mlogloss:0.12714\n",
            "[175]\ttrain-mlogloss:0.00918\tvalid-mlogloss:0.12716\n",
            "[176]\ttrain-mlogloss:0.00918\tvalid-mlogloss:0.12716\n",
            "[177]\ttrain-mlogloss:0.00917\tvalid-mlogloss:0.12714\n",
            "[178]\ttrain-mlogloss:0.00916\tvalid-mlogloss:0.12715\n",
            "[179]\ttrain-mlogloss:0.00915\tvalid-mlogloss:0.12716\n",
            "[180]\ttrain-mlogloss:0.00915\tvalid-mlogloss:0.12718\n",
            "[181]\ttrain-mlogloss:0.00914\tvalid-mlogloss:0.12717\n",
            "[182]\ttrain-mlogloss:0.00913\tvalid-mlogloss:0.12717\n",
            "[183]\ttrain-mlogloss:0.00913\tvalid-mlogloss:0.12718\n",
            "[184]\ttrain-mlogloss:0.00912\tvalid-mlogloss:0.12717\n",
            "[185]\ttrain-mlogloss:0.00911\tvalid-mlogloss:0.12717\n",
            "[186]\ttrain-mlogloss:0.00911\tvalid-mlogloss:0.12717\n",
            "[187]\ttrain-mlogloss:0.00910\tvalid-mlogloss:0.12718\n",
            "[188]\ttrain-mlogloss:0.00909\tvalid-mlogloss:0.12719\n",
            "[189]\ttrain-mlogloss:0.00909\tvalid-mlogloss:0.12720\n",
            "[190]\ttrain-mlogloss:0.00908\tvalid-mlogloss:0.12719\n",
            "[191]\ttrain-mlogloss:0.00908\tvalid-mlogloss:0.12719\n",
            "[192]\ttrain-mlogloss:0.00907\tvalid-mlogloss:0.12718\n",
            "[193]\ttrain-mlogloss:0.00907\tvalid-mlogloss:0.12718\n",
            "[194]\ttrain-mlogloss:0.00906\tvalid-mlogloss:0.12719\n",
            "[195]\ttrain-mlogloss:0.00906\tvalid-mlogloss:0.12719\n",
            "[196]\ttrain-mlogloss:0.00905\tvalid-mlogloss:0.12720\n",
            "[197]\ttrain-mlogloss:0.00905\tvalid-mlogloss:0.12721\n",
            "[198]\ttrain-mlogloss:0.00904\tvalid-mlogloss:0.12722\n",
            "[199]\ttrain-mlogloss:0.00904\tvalid-mlogloss:0.12722\n",
            "[200]\ttrain-mlogloss:0.00903\tvalid-mlogloss:0.12723\n",
            "[201]\ttrain-mlogloss:0.00903\tvalid-mlogloss:0.12723\n",
            "[202]\ttrain-mlogloss:0.00902\tvalid-mlogloss:0.12723\n",
            "[203]\ttrain-mlogloss:0.00902\tvalid-mlogloss:0.12723\n",
            "[204]\ttrain-mlogloss:0.00901\tvalid-mlogloss:0.12723\n",
            "[205]\ttrain-mlogloss:0.00901\tvalid-mlogloss:0.12725\n",
            "[206]\ttrain-mlogloss:0.00900\tvalid-mlogloss:0.12726\n",
            "[207]\ttrain-mlogloss:0.00900\tvalid-mlogloss:0.12726\n",
            "[208]\ttrain-mlogloss:0.00900\tvalid-mlogloss:0.12727\n",
            "[209]\ttrain-mlogloss:0.00899\tvalid-mlogloss:0.12728\n",
            "[210]\ttrain-mlogloss:0.00899\tvalid-mlogloss:0.12730\n",
            "[211]\ttrain-mlogloss:0.00898\tvalid-mlogloss:0.12730\n",
            "[212]\ttrain-mlogloss:0.00898\tvalid-mlogloss:0.12731\n",
            "[213]\ttrain-mlogloss:0.00898\tvalid-mlogloss:0.12731\n",
            "[214]\ttrain-mlogloss:0.00897\tvalid-mlogloss:0.12732\n",
            "[215]\ttrain-mlogloss:0.00897\tvalid-mlogloss:0.12733\n",
            "[216]\ttrain-mlogloss:0.00896\tvalid-mlogloss:0.12733\n",
            "[217]\ttrain-mlogloss:0.00896\tvalid-mlogloss:0.12733\n",
            "[218]\ttrain-mlogloss:0.00896\tvalid-mlogloss:0.12734\n",
            "[219]\ttrain-mlogloss:0.00895\tvalid-mlogloss:0.12734\n",
            "[220]\ttrain-mlogloss:0.00895\tvalid-mlogloss:0.12734\n",
            "[221]\ttrain-mlogloss:0.00895\tvalid-mlogloss:0.12735\n",
            "[222]\ttrain-mlogloss:0.00894\tvalid-mlogloss:0.12736\n",
            "[223]\ttrain-mlogloss:0.00894\tvalid-mlogloss:0.12738\n",
            "[224]\ttrain-mlogloss:0.00894\tvalid-mlogloss:0.12739\n",
            "[225]\ttrain-mlogloss:0.00893\tvalid-mlogloss:0.12741\n",
            "[226]\ttrain-mlogloss:0.00893\tvalid-mlogloss:0.12741\n",
            "[227]\ttrain-mlogloss:0.00893\tvalid-mlogloss:0.12741\n",
            "[228]\ttrain-mlogloss:0.00892\tvalid-mlogloss:0.12743\n",
            "[229]\ttrain-mlogloss:0.00892\tvalid-mlogloss:0.12744\n",
            "[230]\ttrain-mlogloss:0.00892\tvalid-mlogloss:0.12745\n",
            "[231]\ttrain-mlogloss:0.00891\tvalid-mlogloss:0.12745\n",
            "[232]\ttrain-mlogloss:0.00891\tvalid-mlogloss:0.12745\n",
            "[233]\ttrain-mlogloss:0.00891\tvalid-mlogloss:0.12746\n",
            "[234]\ttrain-mlogloss:0.00891\tvalid-mlogloss:0.12746\n",
            "[235]\ttrain-mlogloss:0.00890\tvalid-mlogloss:0.12746\n",
            "[236]\ttrain-mlogloss:0.00890\tvalid-mlogloss:0.12746\n",
            "[237]\ttrain-mlogloss:0.00890\tvalid-mlogloss:0.12748\n",
            "[238]\ttrain-mlogloss:0.00889\tvalid-mlogloss:0.12747\n",
            "[239]\ttrain-mlogloss:0.00889\tvalid-mlogloss:0.12748\n",
            "[240]\ttrain-mlogloss:0.00889\tvalid-mlogloss:0.12748\n",
            "[241]\ttrain-mlogloss:0.00889\tvalid-mlogloss:0.12748\n",
            "[242]\ttrain-mlogloss:0.00888\tvalid-mlogloss:0.12750\n",
            "[243]\ttrain-mlogloss:0.00888\tvalid-mlogloss:0.12750\n",
            "[244]\ttrain-mlogloss:0.00888\tvalid-mlogloss:0.12751\n",
            "[245]\ttrain-mlogloss:0.00888\tvalid-mlogloss:0.12753\n",
            "[246]\ttrain-mlogloss:0.00887\tvalid-mlogloss:0.12753\n",
            "[247]\ttrain-mlogloss:0.00887\tvalid-mlogloss:0.12753\n",
            "[248]\ttrain-mlogloss:0.00887\tvalid-mlogloss:0.12753\n",
            "[checkpoint] saved /content/drive/MyDrive/Stanford/CS229/Final Project/llama+udmp-densityclustering_synthetic cases/xgb_checkpoints/xgb_fold1_0250.json\n",
            "[249]\ttrain-mlogloss:0.00887\tvalid-mlogloss:0.12753\n",
            "[250]\ttrain-mlogloss:0.00886\tvalid-mlogloss:0.12754\n",
            "[251]\ttrain-mlogloss:0.00886\tvalid-mlogloss:0.12755\n",
            "[252]\ttrain-mlogloss:0.00886\tvalid-mlogloss:0.12756\n",
            "[253]\ttrain-mlogloss:0.00886\tvalid-mlogloss:0.12757\n",
            "[254]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.12758\n",
            "[255]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.12759\n",
            "[256]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.12761\n",
            "[257]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.12763\n",
            "[258]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.12765\n",
            "[259]\ttrain-mlogloss:0.00884\tvalid-mlogloss:0.12765\n",
            "[260]\ttrain-mlogloss:0.00884\tvalid-mlogloss:0.12766\n",
            "[261]\ttrain-mlogloss:0.00884\tvalid-mlogloss:0.12766\n",
            "[262]\ttrain-mlogloss:0.00884\tvalid-mlogloss:0.12767\n",
            "[263]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.12768\n",
            "[264]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.12768\n",
            "[265]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.12769\n",
            "[266]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.12770\n",
            "✅ Saved final model: /content/drive/MyDrive/Stanford/CS229/Final Project/llama+udmp-densityclustering_synthetic cases/xgb_checkpoints/xgb_fold1_final.json\n",
            "Fold 1 accuracy: 0.9867\n",
            "Best iteration (early stop): 166\n",
            "\n",
            "===== Fold 2 =====\n",
            "➡️  No checkpoint found; starting fresh.\n",
            "[0]\ttrain-mlogloss:5.87033\tvalid-mlogloss:5.95863\n",
            "[1]\ttrain-mlogloss:4.41377\tvalid-mlogloss:4.57767\n",
            "[2]\ttrain-mlogloss:3.15923\tvalid-mlogloss:3.40050\n",
            "[3]\ttrain-mlogloss:2.59970\tvalid-mlogloss:2.87384\n",
            "[4]\ttrain-mlogloss:2.23190\tvalid-mlogloss:2.53285\n",
            "[5]\ttrain-mlogloss:1.95172\tvalid-mlogloss:2.27408\n",
            "[6]\ttrain-mlogloss:1.72621\tvalid-mlogloss:2.06382\n",
            "[7]\ttrain-mlogloss:1.53927\tvalid-mlogloss:1.88969\n",
            "[8]\ttrain-mlogloss:1.38113\tvalid-mlogloss:1.74149\n",
            "[9]\ttrain-mlogloss:1.24472\tvalid-mlogloss:1.61234\n",
            "[10]\ttrain-mlogloss:1.12638\tvalid-mlogloss:1.49976\n",
            "[11]\ttrain-mlogloss:1.02207\tvalid-mlogloss:1.39976\n",
            "[12]\ttrain-mlogloss:0.92979\tvalid-mlogloss:1.30994\n",
            "[13]\ttrain-mlogloss:0.84762\tvalid-mlogloss:1.22914\n",
            "[14]\ttrain-mlogloss:0.77414\tvalid-mlogloss:1.15576\n",
            "[15]\ttrain-mlogloss:0.70811\tvalid-mlogloss:1.08889\n",
            "[16]\ttrain-mlogloss:0.64850\tvalid-mlogloss:1.02765\n",
            "[17]\ttrain-mlogloss:0.59464\tvalid-mlogloss:0.97188\n",
            "[18]\ttrain-mlogloss:0.54583\tvalid-mlogloss:0.91994\n",
            "[19]\ttrain-mlogloss:0.50146\tvalid-mlogloss:0.87197\n",
            "[20]\ttrain-mlogloss:0.46115\tvalid-mlogloss:0.82744\n",
            "[21]\ttrain-mlogloss:0.42447\tvalid-mlogloss:0.78607\n",
            "[22]\ttrain-mlogloss:0.39097\tvalid-mlogloss:0.74765\n",
            "[23]\ttrain-mlogloss:0.36047\tvalid-mlogloss:0.71183\n",
            "[24]\ttrain-mlogloss:0.33256\tvalid-mlogloss:0.67846\n",
            "[25]\ttrain-mlogloss:0.30703\tvalid-mlogloss:0.64736\n",
            "[26]\ttrain-mlogloss:0.28368\tvalid-mlogloss:0.61815\n",
            "[27]\ttrain-mlogloss:0.26229\tvalid-mlogloss:0.59093\n",
            "[28]\ttrain-mlogloss:0.24272\tvalid-mlogloss:0.56548\n",
            "[29]\ttrain-mlogloss:0.22478\tvalid-mlogloss:0.54176\n",
            "[30]\ttrain-mlogloss:0.20831\tvalid-mlogloss:0.51928\n",
            "[31]\ttrain-mlogloss:0.19324\tvalid-mlogloss:0.49829\n",
            "[32]\ttrain-mlogloss:0.17940\tvalid-mlogloss:0.47852\n",
            "[33]\ttrain-mlogloss:0.16664\tvalid-mlogloss:0.45997\n",
            "[34]\ttrain-mlogloss:0.15497\tvalid-mlogloss:0.44245\n",
            "[35]\ttrain-mlogloss:0.14425\tvalid-mlogloss:0.42605\n",
            "[36]\ttrain-mlogloss:0.13439\tvalid-mlogloss:0.41037\n",
            "[37]\ttrain-mlogloss:0.12528\tvalid-mlogloss:0.39563\n",
            "[38]\ttrain-mlogloss:0.11689\tvalid-mlogloss:0.38176\n",
            "[39]\ttrain-mlogloss:0.10916\tvalid-mlogloss:0.36865\n",
            "[40]\ttrain-mlogloss:0.10206\tvalid-mlogloss:0.35627\n",
            "[41]\ttrain-mlogloss:0.09550\tvalid-mlogloss:0.34449\n",
            "[42]\ttrain-mlogloss:0.08944\tvalid-mlogloss:0.33317\n",
            "[43]\ttrain-mlogloss:0.08386\tvalid-mlogloss:0.32269\n",
            "[44]\ttrain-mlogloss:0.07871\tvalid-mlogloss:0.31272\n",
            "[45]\ttrain-mlogloss:0.07396\tvalid-mlogloss:0.30323\n",
            "[46]\ttrain-mlogloss:0.06956\tvalid-mlogloss:0.29426\n",
            "[47]\ttrain-mlogloss:0.06550\tvalid-mlogloss:0.28579\n",
            "[48]\ttrain-mlogloss:0.06174\tvalid-mlogloss:0.27764\n",
            "[49]\ttrain-mlogloss:0.05827\tvalid-mlogloss:0.26994\n",
            "[50]\ttrain-mlogloss:0.05505\tvalid-mlogloss:0.26269\n",
            "[51]\ttrain-mlogloss:0.05208\tvalid-mlogloss:0.25577\n",
            "[52]\ttrain-mlogloss:0.04933\tvalid-mlogloss:0.24926\n",
            "[53]\ttrain-mlogloss:0.04678\tvalid-mlogloss:0.24312\n",
            "[54]\ttrain-mlogloss:0.04442\tvalid-mlogloss:0.23725\n",
            "[55]\ttrain-mlogloss:0.04223\tvalid-mlogloss:0.23166\n",
            "[56]\ttrain-mlogloss:0.04019\tvalid-mlogloss:0.22643\n",
            "[57]\ttrain-mlogloss:0.03830\tvalid-mlogloss:0.22137\n",
            "[58]\ttrain-mlogloss:0.03654\tvalid-mlogloss:0.21663\n",
            "[59]\ttrain-mlogloss:0.03490\tvalid-mlogloss:0.21205\n",
            "[60]\ttrain-mlogloss:0.03337\tvalid-mlogloss:0.20781\n",
            "[61]\ttrain-mlogloss:0.03195\tvalid-mlogloss:0.20356\n",
            "[62]\ttrain-mlogloss:0.03062\tvalid-mlogloss:0.19958\n",
            "[63]\ttrain-mlogloss:0.02939\tvalid-mlogloss:0.19589\n",
            "[64]\ttrain-mlogloss:0.02823\tvalid-mlogloss:0.19229\n",
            "[65]\ttrain-mlogloss:0.02713\tvalid-mlogloss:0.18882\n",
            "[66]\ttrain-mlogloss:0.02611\tvalid-mlogloss:0.18557\n",
            "[67]\ttrain-mlogloss:0.02515\tvalid-mlogloss:0.18239\n",
            "[68]\ttrain-mlogloss:0.02423\tvalid-mlogloss:0.17938\n",
            "[69]\ttrain-mlogloss:0.02337\tvalid-mlogloss:0.17648\n",
            "[70]\ttrain-mlogloss:0.02257\tvalid-mlogloss:0.17369\n",
            "[71]\ttrain-mlogloss:0.02181\tvalid-mlogloss:0.17104\n",
            "[72]\ttrain-mlogloss:0.02110\tvalid-mlogloss:0.16854\n",
            "[73]\ttrain-mlogloss:0.02043\tvalid-mlogloss:0.16609\n",
            "[74]\ttrain-mlogloss:0.01979\tvalid-mlogloss:0.16373\n",
            "[75]\ttrain-mlogloss:0.01920\tvalid-mlogloss:0.16149\n",
            "[76]\ttrain-mlogloss:0.01863\tvalid-mlogloss:0.15934\n",
            "[77]\ttrain-mlogloss:0.01810\tvalid-mlogloss:0.15731\n",
            "[78]\ttrain-mlogloss:0.01759\tvalid-mlogloss:0.15541\n",
            "[79]\ttrain-mlogloss:0.01711\tvalid-mlogloss:0.15359\n",
            "[80]\ttrain-mlogloss:0.01666\tvalid-mlogloss:0.15191\n",
            "[81]\ttrain-mlogloss:0.01624\tvalid-mlogloss:0.15023\n",
            "[82]\ttrain-mlogloss:0.01584\tvalid-mlogloss:0.14865\n",
            "[83]\ttrain-mlogloss:0.01547\tvalid-mlogloss:0.14717\n",
            "[84]\ttrain-mlogloss:0.01512\tvalid-mlogloss:0.14582\n",
            "[85]\ttrain-mlogloss:0.01479\tvalid-mlogloss:0.14445\n",
            "[86]\ttrain-mlogloss:0.01447\tvalid-mlogloss:0.14317\n",
            "[87]\ttrain-mlogloss:0.01418\tvalid-mlogloss:0.14196\n",
            "[88]\ttrain-mlogloss:0.01390\tvalid-mlogloss:0.14083\n",
            "[89]\ttrain-mlogloss:0.01363\tvalid-mlogloss:0.13972\n",
            "[90]\ttrain-mlogloss:0.01338\tvalid-mlogloss:0.13867\n",
            "[91]\ttrain-mlogloss:0.01314\tvalid-mlogloss:0.13768\n",
            "[92]\ttrain-mlogloss:0.01292\tvalid-mlogloss:0.13675\n",
            "[93]\ttrain-mlogloss:0.01271\tvalid-mlogloss:0.13593\n",
            "[94]\ttrain-mlogloss:0.01251\tvalid-mlogloss:0.13512\n",
            "[95]\ttrain-mlogloss:0.01233\tvalid-mlogloss:0.13439\n",
            "[96]\ttrain-mlogloss:0.01216\tvalid-mlogloss:0.13368\n",
            "[97]\ttrain-mlogloss:0.01199\tvalid-mlogloss:0.13303\n",
            "[98]\ttrain-mlogloss:0.01184\tvalid-mlogloss:0.13243\n",
            "[99]\ttrain-mlogloss:0.01170\tvalid-mlogloss:0.13187\n",
            "[100]\ttrain-mlogloss:0.01157\tvalid-mlogloss:0.13136\n",
            "[101]\ttrain-mlogloss:0.01144\tvalid-mlogloss:0.13088\n",
            "[102]\ttrain-mlogloss:0.01133\tvalid-mlogloss:0.13042\n",
            "[103]\ttrain-mlogloss:0.01122\tvalid-mlogloss:0.13001\n",
            "[104]\ttrain-mlogloss:0.01112\tvalid-mlogloss:0.12965\n",
            "[105]\ttrain-mlogloss:0.01102\tvalid-mlogloss:0.12930\n",
            "[106]\ttrain-mlogloss:0.01094\tvalid-mlogloss:0.12896\n",
            "[107]\ttrain-mlogloss:0.01085\tvalid-mlogloss:0.12866\n",
            "[108]\ttrain-mlogloss:0.01077\tvalid-mlogloss:0.12838\n",
            "[109]\ttrain-mlogloss:0.01070\tvalid-mlogloss:0.12813\n",
            "[110]\ttrain-mlogloss:0.01063\tvalid-mlogloss:0.12786\n",
            "[111]\ttrain-mlogloss:0.01056\tvalid-mlogloss:0.12763\n",
            "[112]\ttrain-mlogloss:0.01050\tvalid-mlogloss:0.12742\n",
            "[113]\ttrain-mlogloss:0.01044\tvalid-mlogloss:0.12722\n",
            "[114]\ttrain-mlogloss:0.01039\tvalid-mlogloss:0.12702\n",
            "[115]\ttrain-mlogloss:0.01034\tvalid-mlogloss:0.12685\n",
            "[116]\ttrain-mlogloss:0.01028\tvalid-mlogloss:0.12671\n",
            "[117]\ttrain-mlogloss:0.01024\tvalid-mlogloss:0.12657\n",
            "[118]\ttrain-mlogloss:0.01019\tvalid-mlogloss:0.12641\n",
            "[119]\ttrain-mlogloss:0.01015\tvalid-mlogloss:0.12630\n",
            "[120]\ttrain-mlogloss:0.01011\tvalid-mlogloss:0.12617\n",
            "[121]\ttrain-mlogloss:0.01007\tvalid-mlogloss:0.12604\n",
            "[122]\ttrain-mlogloss:0.01003\tvalid-mlogloss:0.12593\n",
            "[123]\ttrain-mlogloss:0.01000\tvalid-mlogloss:0.12582\n",
            "[124]\ttrain-mlogloss:0.00997\tvalid-mlogloss:0.12573\n",
            "[125]\ttrain-mlogloss:0.00993\tvalid-mlogloss:0.12561\n",
            "[126]\ttrain-mlogloss:0.00990\tvalid-mlogloss:0.12553\n",
            "[127]\ttrain-mlogloss:0.00987\tvalid-mlogloss:0.12543\n",
            "[128]\ttrain-mlogloss:0.00984\tvalid-mlogloss:0.12534\n",
            "[129]\ttrain-mlogloss:0.00981\tvalid-mlogloss:0.12529\n",
            "[130]\ttrain-mlogloss:0.00979\tvalid-mlogloss:0.12524\n",
            "[131]\ttrain-mlogloss:0.00976\tvalid-mlogloss:0.12518\n",
            "[132]\ttrain-mlogloss:0.00974\tvalid-mlogloss:0.12513\n",
            "[133]\ttrain-mlogloss:0.00972\tvalid-mlogloss:0.12509\n",
            "[134]\ttrain-mlogloss:0.00969\tvalid-mlogloss:0.12501\n",
            "[135]\ttrain-mlogloss:0.00967\tvalid-mlogloss:0.12498\n",
            "[136]\ttrain-mlogloss:0.00965\tvalid-mlogloss:0.12492\n",
            "[137]\ttrain-mlogloss:0.00963\tvalid-mlogloss:0.12486\n",
            "[138]\ttrain-mlogloss:0.00961\tvalid-mlogloss:0.12483\n",
            "[139]\ttrain-mlogloss:0.00959\tvalid-mlogloss:0.12480\n",
            "[140]\ttrain-mlogloss:0.00957\tvalid-mlogloss:0.12476\n",
            "[141]\ttrain-mlogloss:0.00956\tvalid-mlogloss:0.12472\n",
            "[142]\ttrain-mlogloss:0.00954\tvalid-mlogloss:0.12468\n",
            "[143]\ttrain-mlogloss:0.00952\tvalid-mlogloss:0.12467\n",
            "[144]\ttrain-mlogloss:0.00951\tvalid-mlogloss:0.12465\n",
            "[145]\ttrain-mlogloss:0.00949\tvalid-mlogloss:0.12461\n",
            "[146]\ttrain-mlogloss:0.00947\tvalid-mlogloss:0.12458\n",
            "[147]\ttrain-mlogloss:0.00946\tvalid-mlogloss:0.12456\n",
            "[148]\ttrain-mlogloss:0.00944\tvalid-mlogloss:0.12453\n",
            "[149]\ttrain-mlogloss:0.00943\tvalid-mlogloss:0.12449\n",
            "[150]\ttrain-mlogloss:0.00942\tvalid-mlogloss:0.12446\n",
            "[151]\ttrain-mlogloss:0.00940\tvalid-mlogloss:0.12445\n",
            "[152]\ttrain-mlogloss:0.00939\tvalid-mlogloss:0.12444\n",
            "[153]\ttrain-mlogloss:0.00938\tvalid-mlogloss:0.12442\n",
            "[154]\ttrain-mlogloss:0.00936\tvalid-mlogloss:0.12442\n",
            "[155]\ttrain-mlogloss:0.00935\tvalid-mlogloss:0.12439\n",
            "[156]\ttrain-mlogloss:0.00934\tvalid-mlogloss:0.12438\n",
            "[157]\ttrain-mlogloss:0.00933\tvalid-mlogloss:0.12437\n",
            "[158]\ttrain-mlogloss:0.00932\tvalid-mlogloss:0.12436\n",
            "[159]\ttrain-mlogloss:0.00931\tvalid-mlogloss:0.12435\n",
            "[160]\ttrain-mlogloss:0.00930\tvalid-mlogloss:0.12435\n",
            "[161]\ttrain-mlogloss:0.00929\tvalid-mlogloss:0.12433\n",
            "[162]\ttrain-mlogloss:0.00928\tvalid-mlogloss:0.12430\n",
            "[163]\ttrain-mlogloss:0.00927\tvalid-mlogloss:0.12428\n",
            "[164]\ttrain-mlogloss:0.00926\tvalid-mlogloss:0.12427\n",
            "[165]\ttrain-mlogloss:0.00925\tvalid-mlogloss:0.12426\n",
            "[166]\ttrain-mlogloss:0.00924\tvalid-mlogloss:0.12424\n",
            "[167]\ttrain-mlogloss:0.00923\tvalid-mlogloss:0.12423\n",
            "[168]\ttrain-mlogloss:0.00922\tvalid-mlogloss:0.12421\n",
            "[169]\ttrain-mlogloss:0.00921\tvalid-mlogloss:0.12421\n",
            "[170]\ttrain-mlogloss:0.00921\tvalid-mlogloss:0.12420\n",
            "[171]\ttrain-mlogloss:0.00920\tvalid-mlogloss:0.12420\n",
            "[172]\ttrain-mlogloss:0.00919\tvalid-mlogloss:0.12421\n",
            "[173]\ttrain-mlogloss:0.00918\tvalid-mlogloss:0.12420\n",
            "[174]\ttrain-mlogloss:0.00917\tvalid-mlogloss:0.12418\n",
            "[175]\ttrain-mlogloss:0.00917\tvalid-mlogloss:0.12417\n",
            "[176]\ttrain-mlogloss:0.00916\tvalid-mlogloss:0.12415\n",
            "[177]\ttrain-mlogloss:0.00915\tvalid-mlogloss:0.12415\n",
            "[178]\ttrain-mlogloss:0.00915\tvalid-mlogloss:0.12414\n",
            "[179]\ttrain-mlogloss:0.00914\tvalid-mlogloss:0.12414\n",
            "[180]\ttrain-mlogloss:0.00913\tvalid-mlogloss:0.12412\n",
            "[181]\ttrain-mlogloss:0.00913\tvalid-mlogloss:0.12411\n",
            "[182]\ttrain-mlogloss:0.00912\tvalid-mlogloss:0.12409\n",
            "[183]\ttrain-mlogloss:0.00911\tvalid-mlogloss:0.12409\n",
            "[184]\ttrain-mlogloss:0.00911\tvalid-mlogloss:0.12408\n",
            "[185]\ttrain-mlogloss:0.00910\tvalid-mlogloss:0.12406\n",
            "[186]\ttrain-mlogloss:0.00909\tvalid-mlogloss:0.12406\n",
            "[187]\ttrain-mlogloss:0.00909\tvalid-mlogloss:0.12408\n",
            "[188]\ttrain-mlogloss:0.00908\tvalid-mlogloss:0.12406\n",
            "[189]\ttrain-mlogloss:0.00908\tvalid-mlogloss:0.12406\n",
            "[190]\ttrain-mlogloss:0.00907\tvalid-mlogloss:0.12405\n",
            "[191]\ttrain-mlogloss:0.00907\tvalid-mlogloss:0.12406\n",
            "[192]\ttrain-mlogloss:0.00906\tvalid-mlogloss:0.12403\n",
            "[193]\ttrain-mlogloss:0.00906\tvalid-mlogloss:0.12402\n",
            "[194]\ttrain-mlogloss:0.00905\tvalid-mlogloss:0.12403\n",
            "[195]\ttrain-mlogloss:0.00904\tvalid-mlogloss:0.12402\n",
            "[196]\ttrain-mlogloss:0.00904\tvalid-mlogloss:0.12401\n",
            "[197]\ttrain-mlogloss:0.00903\tvalid-mlogloss:0.12402\n",
            "[198]\ttrain-mlogloss:0.00903\tvalid-mlogloss:0.12403\n",
            "[199]\ttrain-mlogloss:0.00902\tvalid-mlogloss:0.12403\n",
            "[200]\ttrain-mlogloss:0.00902\tvalid-mlogloss:0.12403\n",
            "[201]\ttrain-mlogloss:0.00902\tvalid-mlogloss:0.12403\n",
            "[202]\ttrain-mlogloss:0.00901\tvalid-mlogloss:0.12403\n",
            "[203]\ttrain-mlogloss:0.00901\tvalid-mlogloss:0.12403\n",
            "[204]\ttrain-mlogloss:0.00900\tvalid-mlogloss:0.12402\n",
            "[205]\ttrain-mlogloss:0.00900\tvalid-mlogloss:0.12403\n",
            "[206]\ttrain-mlogloss:0.00899\tvalid-mlogloss:0.12405\n",
            "[207]\ttrain-mlogloss:0.00899\tvalid-mlogloss:0.12406\n",
            "[208]\ttrain-mlogloss:0.00899\tvalid-mlogloss:0.12406\n",
            "[209]\ttrain-mlogloss:0.00898\tvalid-mlogloss:0.12407\n",
            "[210]\ttrain-mlogloss:0.00898\tvalid-mlogloss:0.12407\n",
            "[211]\ttrain-mlogloss:0.00897\tvalid-mlogloss:0.12408\n",
            "[212]\ttrain-mlogloss:0.00897\tvalid-mlogloss:0.12408\n",
            "[213]\ttrain-mlogloss:0.00897\tvalid-mlogloss:0.12409\n",
            "[214]\ttrain-mlogloss:0.00896\tvalid-mlogloss:0.12409\n",
            "[215]\ttrain-mlogloss:0.00896\tvalid-mlogloss:0.12410\n",
            "[216]\ttrain-mlogloss:0.00895\tvalid-mlogloss:0.12409\n",
            "[217]\ttrain-mlogloss:0.00895\tvalid-mlogloss:0.12410\n",
            "[218]\ttrain-mlogloss:0.00895\tvalid-mlogloss:0.12410\n",
            "[219]\ttrain-mlogloss:0.00894\tvalid-mlogloss:0.12411\n",
            "[220]\ttrain-mlogloss:0.00894\tvalid-mlogloss:0.12412\n",
            "[221]\ttrain-mlogloss:0.00894\tvalid-mlogloss:0.12412\n",
            "[222]\ttrain-mlogloss:0.00893\tvalid-mlogloss:0.12412\n",
            "[223]\ttrain-mlogloss:0.00893\tvalid-mlogloss:0.12413\n",
            "[224]\ttrain-mlogloss:0.00893\tvalid-mlogloss:0.12413\n",
            "[225]\ttrain-mlogloss:0.00892\tvalid-mlogloss:0.12413\n",
            "[226]\ttrain-mlogloss:0.00892\tvalid-mlogloss:0.12413\n",
            "[227]\ttrain-mlogloss:0.00892\tvalid-mlogloss:0.12413\n",
            "[228]\ttrain-mlogloss:0.00891\tvalid-mlogloss:0.12415\n",
            "[229]\ttrain-mlogloss:0.00891\tvalid-mlogloss:0.12414\n",
            "[230]\ttrain-mlogloss:0.00891\tvalid-mlogloss:0.12414\n",
            "[231]\ttrain-mlogloss:0.00891\tvalid-mlogloss:0.12414\n",
            "[232]\ttrain-mlogloss:0.00890\tvalid-mlogloss:0.12414\n",
            "[233]\ttrain-mlogloss:0.00890\tvalid-mlogloss:0.12414\n",
            "[234]\ttrain-mlogloss:0.00890\tvalid-mlogloss:0.12414\n",
            "[235]\ttrain-mlogloss:0.00889\tvalid-mlogloss:0.12415\n",
            "[236]\ttrain-mlogloss:0.00889\tvalid-mlogloss:0.12415\n",
            "[237]\ttrain-mlogloss:0.00889\tvalid-mlogloss:0.12417\n",
            "[238]\ttrain-mlogloss:0.00889\tvalid-mlogloss:0.12418\n",
            "[239]\ttrain-mlogloss:0.00888\tvalid-mlogloss:0.12419\n",
            "[240]\ttrain-mlogloss:0.00888\tvalid-mlogloss:0.12419\n",
            "[241]\ttrain-mlogloss:0.00888\tvalid-mlogloss:0.12419\n",
            "[242]\ttrain-mlogloss:0.00888\tvalid-mlogloss:0.12420\n",
            "[243]\ttrain-mlogloss:0.00887\tvalid-mlogloss:0.12419\n",
            "[244]\ttrain-mlogloss:0.00887\tvalid-mlogloss:0.12420\n",
            "[245]\ttrain-mlogloss:0.00887\tvalid-mlogloss:0.12420\n",
            "[246]\ttrain-mlogloss:0.00887\tvalid-mlogloss:0.12420\n",
            "[247]\ttrain-mlogloss:0.00886\tvalid-mlogloss:0.12420\n",
            "[248]\ttrain-mlogloss:0.00886\tvalid-mlogloss:0.12420\n",
            "[checkpoint] saved /content/drive/MyDrive/Stanford/CS229/Final Project/llama+udmp-densityclustering_synthetic cases/xgb_checkpoints/xgb_fold2_0250.json\n",
            "[249]\ttrain-mlogloss:0.00886\tvalid-mlogloss:0.12420\n",
            "[250]\ttrain-mlogloss:0.00886\tvalid-mlogloss:0.12420\n",
            "[251]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.12421\n",
            "[252]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.12421\n",
            "[253]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.12422\n",
            "[254]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.12422\n",
            "[255]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.12421\n",
            "[256]\ttrain-mlogloss:0.00884\tvalid-mlogloss:0.12421\n",
            "[257]\ttrain-mlogloss:0.00884\tvalid-mlogloss:0.12421\n",
            "[258]\ttrain-mlogloss:0.00884\tvalid-mlogloss:0.12420\n",
            "[259]\ttrain-mlogloss:0.00884\tvalid-mlogloss:0.12421\n",
            "[260]\ttrain-mlogloss:0.00884\tvalid-mlogloss:0.12422\n",
            "[261]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.12422\n",
            "[262]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.12423\n",
            "[263]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.12422\n",
            "[264]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.12423\n",
            "[265]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.12423\n",
            "[266]\ttrain-mlogloss:0.00882\tvalid-mlogloss:0.12423\n",
            "[267]\ttrain-mlogloss:0.00882\tvalid-mlogloss:0.12423\n",
            "[268]\ttrain-mlogloss:0.00882\tvalid-mlogloss:0.12424\n",
            "[269]\ttrain-mlogloss:0.00882\tvalid-mlogloss:0.12425\n",
            "[270]\ttrain-mlogloss:0.00882\tvalid-mlogloss:0.12425\n",
            "[271]\ttrain-mlogloss:0.00881\tvalid-mlogloss:0.12426\n",
            "[272]\ttrain-mlogloss:0.00881\tvalid-mlogloss:0.12427\n",
            "[273]\ttrain-mlogloss:0.00881\tvalid-mlogloss:0.12427\n",
            "[274]\ttrain-mlogloss:0.00881\tvalid-mlogloss:0.12428\n",
            "[275]\ttrain-mlogloss:0.00881\tvalid-mlogloss:0.12429\n",
            "[276]\ttrain-mlogloss:0.00880\tvalid-mlogloss:0.12431\n",
            "[277]\ttrain-mlogloss:0.00880\tvalid-mlogloss:0.12430\n",
            "[278]\ttrain-mlogloss:0.00880\tvalid-mlogloss:0.12430\n",
            "[279]\ttrain-mlogloss:0.00880\tvalid-mlogloss:0.12430\n",
            "[280]\ttrain-mlogloss:0.00880\tvalid-mlogloss:0.12430\n",
            "[281]\ttrain-mlogloss:0.00880\tvalid-mlogloss:0.12431\n",
            "[282]\ttrain-mlogloss:0.00879\tvalid-mlogloss:0.12433\n",
            "[283]\ttrain-mlogloss:0.00879\tvalid-mlogloss:0.12432\n",
            "[284]\ttrain-mlogloss:0.00879\tvalid-mlogloss:0.12433\n",
            "[285]\ttrain-mlogloss:0.00879\tvalid-mlogloss:0.12432\n",
            "[286]\ttrain-mlogloss:0.00879\tvalid-mlogloss:0.12432\n",
            "[287]\ttrain-mlogloss:0.00879\tvalid-mlogloss:0.12433\n",
            "[288]\ttrain-mlogloss:0.00879\tvalid-mlogloss:0.12433\n",
            "[289]\ttrain-mlogloss:0.00878\tvalid-mlogloss:0.12433\n",
            "[290]\ttrain-mlogloss:0.00878\tvalid-mlogloss:0.12433\n",
            "[291]\ttrain-mlogloss:0.00878\tvalid-mlogloss:0.12434\n",
            "[292]\ttrain-mlogloss:0.00878\tvalid-mlogloss:0.12436\n",
            "[293]\ttrain-mlogloss:0.00878\tvalid-mlogloss:0.12434\n",
            "[294]\ttrain-mlogloss:0.00878\tvalid-mlogloss:0.12436\n",
            "[295]\ttrain-mlogloss:0.00878\tvalid-mlogloss:0.12437\n",
            "[296]\ttrain-mlogloss:0.00877\tvalid-mlogloss:0.12438\n",
            "✅ Saved final model: /content/drive/MyDrive/Stanford/CS229/Final Project/llama+udmp-densityclustering_synthetic cases/xgb_checkpoints/xgb_fold2_final.json\n",
            "Fold 2 accuracy: 0.9870\n",
            "Best iteration (early stop): 196\n",
            "\n",
            "===== Fold 3 =====\n",
            "➡️  No checkpoint found; starting fresh.\n",
            "[0]\ttrain-mlogloss:5.87099\tvalid-mlogloss:5.96013\n",
            "[1]\ttrain-mlogloss:4.42109\tvalid-mlogloss:4.58661\n",
            "[2]\ttrain-mlogloss:3.15332\tvalid-mlogloss:3.39932\n",
            "[3]\ttrain-mlogloss:2.59794\tvalid-mlogloss:2.87547\n",
            "[4]\ttrain-mlogloss:2.23161\tvalid-mlogloss:2.53532\n",
            "[5]\ttrain-mlogloss:1.95112\tvalid-mlogloss:2.27510\n",
            "[6]\ttrain-mlogloss:1.72562\tvalid-mlogloss:2.06539\n",
            "[7]\ttrain-mlogloss:1.53899\tvalid-mlogloss:1.89124\n",
            "[8]\ttrain-mlogloss:1.38093\tvalid-mlogloss:1.74234\n",
            "[9]\ttrain-mlogloss:1.24479\tvalid-mlogloss:1.61351\n",
            "[10]\ttrain-mlogloss:1.12638\tvalid-mlogloss:1.50086\n",
            "[11]\ttrain-mlogloss:1.02225\tvalid-mlogloss:1.40108\n",
            "[12]\ttrain-mlogloss:0.93000\tvalid-mlogloss:1.31094\n",
            "[13]\ttrain-mlogloss:0.84786\tvalid-mlogloss:1.22954\n",
            "[14]\ttrain-mlogloss:0.77442\tvalid-mlogloss:1.15590\n",
            "[15]\ttrain-mlogloss:0.70836\tvalid-mlogloss:1.08947\n",
            "[16]\ttrain-mlogloss:0.64883\tvalid-mlogloss:1.02853\n",
            "[17]\ttrain-mlogloss:0.59493\tvalid-mlogloss:0.97253\n",
            "[18]\ttrain-mlogloss:0.54608\tvalid-mlogloss:0.92087\n",
            "[19]\ttrain-mlogloss:0.50180\tvalid-mlogloss:0.87306\n",
            "[20]\ttrain-mlogloss:0.46147\tvalid-mlogloss:0.82860\n",
            "[21]\ttrain-mlogloss:0.42480\tvalid-mlogloss:0.78740\n",
            "[22]\ttrain-mlogloss:0.39138\tvalid-mlogloss:0.74946\n",
            "[23]\ttrain-mlogloss:0.36087\tvalid-mlogloss:0.71396\n",
            "[24]\ttrain-mlogloss:0.33301\tvalid-mlogloss:0.68084\n",
            "[25]\ttrain-mlogloss:0.30751\tvalid-mlogloss:0.64985\n",
            "[26]\ttrain-mlogloss:0.28418\tvalid-mlogloss:0.62076\n",
            "[27]\ttrain-mlogloss:0.26281\tvalid-mlogloss:0.59377\n",
            "[28]\ttrain-mlogloss:0.24318\tvalid-mlogloss:0.56820\n",
            "[29]\ttrain-mlogloss:0.22523\tvalid-mlogloss:0.54432\n",
            "[30]\ttrain-mlogloss:0.20874\tvalid-mlogloss:0.52176\n",
            "[31]\ttrain-mlogloss:0.19364\tvalid-mlogloss:0.50072\n",
            "[32]\ttrain-mlogloss:0.17973\tvalid-mlogloss:0.48091\n",
            "[33]\ttrain-mlogloss:0.16698\tvalid-mlogloss:0.46216\n",
            "[34]\ttrain-mlogloss:0.15529\tvalid-mlogloss:0.44456\n",
            "[35]\ttrain-mlogloss:0.14453\tvalid-mlogloss:0.42812\n",
            "[36]\ttrain-mlogloss:0.13466\tvalid-mlogloss:0.41246\n",
            "[37]\ttrain-mlogloss:0.12554\tvalid-mlogloss:0.39771\n",
            "[38]\ttrain-mlogloss:0.11716\tvalid-mlogloss:0.38376\n",
            "[39]\ttrain-mlogloss:0.10945\tvalid-mlogloss:0.37056\n",
            "[40]\ttrain-mlogloss:0.10231\tvalid-mlogloss:0.35809\n",
            "[41]\ttrain-mlogloss:0.09573\tvalid-mlogloss:0.34625\n",
            "[42]\ttrain-mlogloss:0.08967\tvalid-mlogloss:0.33518\n",
            "[43]\ttrain-mlogloss:0.08408\tvalid-mlogloss:0.32471\n",
            "[44]\ttrain-mlogloss:0.07892\tvalid-mlogloss:0.31464\n",
            "[45]\ttrain-mlogloss:0.07417\tvalid-mlogloss:0.30524\n",
            "[46]\ttrain-mlogloss:0.06976\tvalid-mlogloss:0.29621\n",
            "[47]\ttrain-mlogloss:0.06570\tvalid-mlogloss:0.28779\n",
            "[48]\ttrain-mlogloss:0.06194\tvalid-mlogloss:0.27970\n",
            "[49]\ttrain-mlogloss:0.05845\tvalid-mlogloss:0.27207\n",
            "[50]\ttrain-mlogloss:0.05523\tvalid-mlogloss:0.26487\n",
            "[51]\ttrain-mlogloss:0.05225\tvalid-mlogloss:0.25810\n",
            "[52]\ttrain-mlogloss:0.04949\tvalid-mlogloss:0.25161\n",
            "[53]\ttrain-mlogloss:0.04693\tvalid-mlogloss:0.24545\n",
            "[54]\ttrain-mlogloss:0.04455\tvalid-mlogloss:0.23962\n",
            "[55]\ttrain-mlogloss:0.04236\tvalid-mlogloss:0.23396\n",
            "[56]\ttrain-mlogloss:0.04031\tvalid-mlogloss:0.22873\n",
            "[57]\ttrain-mlogloss:0.03843\tvalid-mlogloss:0.22382\n",
            "[58]\ttrain-mlogloss:0.03666\tvalid-mlogloss:0.21903\n",
            "[59]\ttrain-mlogloss:0.03502\tvalid-mlogloss:0.21450\n",
            "[60]\ttrain-mlogloss:0.03350\tvalid-mlogloss:0.21021\n",
            "[61]\ttrain-mlogloss:0.03206\tvalid-mlogloss:0.20614\n",
            "[62]\ttrain-mlogloss:0.03073\tvalid-mlogloss:0.20214\n",
            "[63]\ttrain-mlogloss:0.02948\tvalid-mlogloss:0.19844\n",
            "[64]\ttrain-mlogloss:0.02830\tvalid-mlogloss:0.19484\n",
            "[65]\ttrain-mlogloss:0.02721\tvalid-mlogloss:0.19140\n",
            "[66]\ttrain-mlogloss:0.02618\tvalid-mlogloss:0.18808\n",
            "[67]\ttrain-mlogloss:0.02520\tvalid-mlogloss:0.18491\n",
            "[68]\ttrain-mlogloss:0.02429\tvalid-mlogloss:0.18194\n",
            "[69]\ttrain-mlogloss:0.02344\tvalid-mlogloss:0.17906\n",
            "[70]\ttrain-mlogloss:0.02263\tvalid-mlogloss:0.17621\n",
            "[71]\ttrain-mlogloss:0.02187\tvalid-mlogloss:0.17348\n",
            "[72]\ttrain-mlogloss:0.02116\tvalid-mlogloss:0.17092\n",
            "[73]\ttrain-mlogloss:0.02048\tvalid-mlogloss:0.16854\n",
            "[74]\ttrain-mlogloss:0.01984\tvalid-mlogloss:0.16616\n",
            "[75]\ttrain-mlogloss:0.01923\tvalid-mlogloss:0.16396\n",
            "[76]\ttrain-mlogloss:0.01866\tvalid-mlogloss:0.16187\n",
            "[77]\ttrain-mlogloss:0.01812\tvalid-mlogloss:0.15981\n",
            "[78]\ttrain-mlogloss:0.01761\tvalid-mlogloss:0.15792\n",
            "[79]\ttrain-mlogloss:0.01714\tvalid-mlogloss:0.15608\n",
            "[80]\ttrain-mlogloss:0.01669\tvalid-mlogloss:0.15434\n",
            "[81]\ttrain-mlogloss:0.01627\tvalid-mlogloss:0.15269\n",
            "[82]\ttrain-mlogloss:0.01587\tvalid-mlogloss:0.15114\n",
            "[83]\ttrain-mlogloss:0.01549\tvalid-mlogloss:0.14966\n",
            "[84]\ttrain-mlogloss:0.01514\tvalid-mlogloss:0.14821\n",
            "[85]\ttrain-mlogloss:0.01480\tvalid-mlogloss:0.14688\n",
            "[86]\ttrain-mlogloss:0.01448\tvalid-mlogloss:0.14561\n",
            "[87]\ttrain-mlogloss:0.01418\tvalid-mlogloss:0.14442\n",
            "[88]\ttrain-mlogloss:0.01390\tvalid-mlogloss:0.14328\n",
            "[89]\ttrain-mlogloss:0.01364\tvalid-mlogloss:0.14220\n",
            "[90]\ttrain-mlogloss:0.01338\tvalid-mlogloss:0.14116\n",
            "[91]\ttrain-mlogloss:0.01314\tvalid-mlogloss:0.14021\n",
            "[92]\ttrain-mlogloss:0.01292\tvalid-mlogloss:0.13933\n",
            "[93]\ttrain-mlogloss:0.01270\tvalid-mlogloss:0.13848\n",
            "[94]\ttrain-mlogloss:0.01251\tvalid-mlogloss:0.13771\n",
            "[95]\ttrain-mlogloss:0.01232\tvalid-mlogloss:0.13699\n",
            "[96]\ttrain-mlogloss:0.01214\tvalid-mlogloss:0.13628\n",
            "[97]\ttrain-mlogloss:0.01198\tvalid-mlogloss:0.13562\n",
            "[98]\ttrain-mlogloss:0.01183\tvalid-mlogloss:0.13504\n",
            "[99]\ttrain-mlogloss:0.01168\tvalid-mlogloss:0.13445\n",
            "[100]\ttrain-mlogloss:0.01155\tvalid-mlogloss:0.13393\n",
            "[101]\ttrain-mlogloss:0.01143\tvalid-mlogloss:0.13342\n",
            "[102]\ttrain-mlogloss:0.01131\tvalid-mlogloss:0.13295\n",
            "[103]\ttrain-mlogloss:0.01120\tvalid-mlogloss:0.13252\n",
            "[104]\ttrain-mlogloss:0.01110\tvalid-mlogloss:0.13213\n",
            "[105]\ttrain-mlogloss:0.01100\tvalid-mlogloss:0.13179\n",
            "[106]\ttrain-mlogloss:0.01091\tvalid-mlogloss:0.13143\n",
            "[107]\ttrain-mlogloss:0.01083\tvalid-mlogloss:0.13113\n",
            "[108]\ttrain-mlogloss:0.01075\tvalid-mlogloss:0.13080\n",
            "[109]\ttrain-mlogloss:0.01067\tvalid-mlogloss:0.13055\n",
            "[110]\ttrain-mlogloss:0.01060\tvalid-mlogloss:0.13027\n",
            "[111]\ttrain-mlogloss:0.01054\tvalid-mlogloss:0.13004\n",
            "[112]\ttrain-mlogloss:0.01047\tvalid-mlogloss:0.12982\n",
            "[113]\ttrain-mlogloss:0.01041\tvalid-mlogloss:0.12963\n",
            "[114]\ttrain-mlogloss:0.01036\tvalid-mlogloss:0.12945\n",
            "[115]\ttrain-mlogloss:0.01031\tvalid-mlogloss:0.12928\n",
            "[116]\ttrain-mlogloss:0.01026\tvalid-mlogloss:0.12910\n",
            "[117]\ttrain-mlogloss:0.01021\tvalid-mlogloss:0.12891\n",
            "[118]\ttrain-mlogloss:0.01016\tvalid-mlogloss:0.12876\n",
            "[119]\ttrain-mlogloss:0.01012\tvalid-mlogloss:0.12863\n",
            "[120]\ttrain-mlogloss:0.01008\tvalid-mlogloss:0.12851\n",
            "[121]\ttrain-mlogloss:0.01004\tvalid-mlogloss:0.12839\n",
            "[122]\ttrain-mlogloss:0.01000\tvalid-mlogloss:0.12828\n",
            "[123]\ttrain-mlogloss:0.00997\tvalid-mlogloss:0.12818\n",
            "[124]\ttrain-mlogloss:0.00993\tvalid-mlogloss:0.12808\n",
            "[125]\ttrain-mlogloss:0.00990\tvalid-mlogloss:0.12797\n",
            "[126]\ttrain-mlogloss:0.00987\tvalid-mlogloss:0.12786\n",
            "[127]\ttrain-mlogloss:0.00984\tvalid-mlogloss:0.12775\n",
            "[128]\ttrain-mlogloss:0.00981\tvalid-mlogloss:0.12765\n",
            "[129]\ttrain-mlogloss:0.00978\tvalid-mlogloss:0.12759\n",
            "[130]\ttrain-mlogloss:0.00976\tvalid-mlogloss:0.12751\n",
            "[131]\ttrain-mlogloss:0.00973\tvalid-mlogloss:0.12744\n",
            "[132]\ttrain-mlogloss:0.00971\tvalid-mlogloss:0.12739\n",
            "[133]\ttrain-mlogloss:0.00969\tvalid-mlogloss:0.12735\n",
            "[134]\ttrain-mlogloss:0.00966\tvalid-mlogloss:0.12729\n",
            "[135]\ttrain-mlogloss:0.00964\tvalid-mlogloss:0.12725\n",
            "[136]\ttrain-mlogloss:0.00962\tvalid-mlogloss:0.12718\n",
            "[137]\ttrain-mlogloss:0.00960\tvalid-mlogloss:0.12713\n",
            "[138]\ttrain-mlogloss:0.00958\tvalid-mlogloss:0.12708\n",
            "[139]\ttrain-mlogloss:0.00956\tvalid-mlogloss:0.12705\n",
            "[140]\ttrain-mlogloss:0.00954\tvalid-mlogloss:0.12703\n",
            "[141]\ttrain-mlogloss:0.00953\tvalid-mlogloss:0.12699\n",
            "[142]\ttrain-mlogloss:0.00951\tvalid-mlogloss:0.12694\n",
            "[143]\ttrain-mlogloss:0.00949\tvalid-mlogloss:0.12691\n",
            "[144]\ttrain-mlogloss:0.00948\tvalid-mlogloss:0.12688\n",
            "[145]\ttrain-mlogloss:0.00946\tvalid-mlogloss:0.12685\n",
            "[146]\ttrain-mlogloss:0.00944\tvalid-mlogloss:0.12683\n",
            "[147]\ttrain-mlogloss:0.00943\tvalid-mlogloss:0.12680\n",
            "[148]\ttrain-mlogloss:0.00942\tvalid-mlogloss:0.12677\n",
            "[149]\ttrain-mlogloss:0.00940\tvalid-mlogloss:0.12676\n",
            "[150]\ttrain-mlogloss:0.00939\tvalid-mlogloss:0.12673\n",
            "[151]\ttrain-mlogloss:0.00937\tvalid-mlogloss:0.12670\n",
            "[152]\ttrain-mlogloss:0.00936\tvalid-mlogloss:0.12667\n",
            "[153]\ttrain-mlogloss:0.00935\tvalid-mlogloss:0.12667\n",
            "[154]\ttrain-mlogloss:0.00934\tvalid-mlogloss:0.12666\n",
            "[155]\ttrain-mlogloss:0.00933\tvalid-mlogloss:0.12665\n",
            "[156]\ttrain-mlogloss:0.00931\tvalid-mlogloss:0.12662\n",
            "[157]\ttrain-mlogloss:0.00930\tvalid-mlogloss:0.12659\n",
            "[158]\ttrain-mlogloss:0.00929\tvalid-mlogloss:0.12657\n",
            "[159]\ttrain-mlogloss:0.00928\tvalid-mlogloss:0.12657\n",
            "[160]\ttrain-mlogloss:0.00927\tvalid-mlogloss:0.12655\n",
            "[161]\ttrain-mlogloss:0.00926\tvalid-mlogloss:0.12655\n",
            "[162]\ttrain-mlogloss:0.00925\tvalid-mlogloss:0.12653\n",
            "[163]\ttrain-mlogloss:0.00924\tvalid-mlogloss:0.12651\n",
            "[164]\ttrain-mlogloss:0.00923\tvalid-mlogloss:0.12651\n",
            "[165]\ttrain-mlogloss:0.00922\tvalid-mlogloss:0.12651\n",
            "[166]\ttrain-mlogloss:0.00921\tvalid-mlogloss:0.12651\n",
            "[167]\ttrain-mlogloss:0.00920\tvalid-mlogloss:0.12651\n",
            "[168]\ttrain-mlogloss:0.00919\tvalid-mlogloss:0.12648\n",
            "[169]\ttrain-mlogloss:0.00918\tvalid-mlogloss:0.12648\n",
            "[170]\ttrain-mlogloss:0.00918\tvalid-mlogloss:0.12647\n",
            "[171]\ttrain-mlogloss:0.00917\tvalid-mlogloss:0.12647\n",
            "[172]\ttrain-mlogloss:0.00916\tvalid-mlogloss:0.12646\n",
            "[173]\ttrain-mlogloss:0.00915\tvalid-mlogloss:0.12645\n",
            "[174]\ttrain-mlogloss:0.00915\tvalid-mlogloss:0.12643\n",
            "[175]\ttrain-mlogloss:0.00914\tvalid-mlogloss:0.12642\n",
            "[176]\ttrain-mlogloss:0.00913\tvalid-mlogloss:0.12641\n",
            "[177]\ttrain-mlogloss:0.00912\tvalid-mlogloss:0.12639\n",
            "[178]\ttrain-mlogloss:0.00912\tvalid-mlogloss:0.12639\n",
            "[179]\ttrain-mlogloss:0.00911\tvalid-mlogloss:0.12638\n",
            "[180]\ttrain-mlogloss:0.00910\tvalid-mlogloss:0.12638\n",
            "[181]\ttrain-mlogloss:0.00910\tvalid-mlogloss:0.12639\n",
            "[182]\ttrain-mlogloss:0.00909\tvalid-mlogloss:0.12641\n",
            "[183]\ttrain-mlogloss:0.00908\tvalid-mlogloss:0.12640\n",
            "[184]\ttrain-mlogloss:0.00908\tvalid-mlogloss:0.12640\n",
            "[185]\ttrain-mlogloss:0.00907\tvalid-mlogloss:0.12640\n",
            "[186]\ttrain-mlogloss:0.00906\tvalid-mlogloss:0.12642\n",
            "[187]\ttrain-mlogloss:0.00906\tvalid-mlogloss:0.12642\n",
            "[188]\ttrain-mlogloss:0.00905\tvalid-mlogloss:0.12642\n",
            "[189]\ttrain-mlogloss:0.00905\tvalid-mlogloss:0.12642\n",
            "[190]\ttrain-mlogloss:0.00904\tvalid-mlogloss:0.12644\n",
            "[191]\ttrain-mlogloss:0.00904\tvalid-mlogloss:0.12643\n",
            "[192]\ttrain-mlogloss:0.00903\tvalid-mlogloss:0.12642\n",
            "[193]\ttrain-mlogloss:0.00903\tvalid-mlogloss:0.12641\n",
            "[194]\ttrain-mlogloss:0.00902\tvalid-mlogloss:0.12643\n",
            "[195]\ttrain-mlogloss:0.00902\tvalid-mlogloss:0.12644\n",
            "[196]\ttrain-mlogloss:0.00901\tvalid-mlogloss:0.12643\n",
            "[197]\ttrain-mlogloss:0.00901\tvalid-mlogloss:0.12643\n",
            "[198]\ttrain-mlogloss:0.00900\tvalid-mlogloss:0.12643\n",
            "[199]\ttrain-mlogloss:0.00900\tvalid-mlogloss:0.12642\n",
            "[200]\ttrain-mlogloss:0.00899\tvalid-mlogloss:0.12642\n",
            "[201]\ttrain-mlogloss:0.00899\tvalid-mlogloss:0.12644\n",
            "[202]\ttrain-mlogloss:0.00898\tvalid-mlogloss:0.12645\n",
            "[203]\ttrain-mlogloss:0.00898\tvalid-mlogloss:0.12644\n",
            "[204]\ttrain-mlogloss:0.00897\tvalid-mlogloss:0.12646\n",
            "[205]\ttrain-mlogloss:0.00897\tvalid-mlogloss:0.12646\n",
            "[206]\ttrain-mlogloss:0.00897\tvalid-mlogloss:0.12646\n",
            "[207]\ttrain-mlogloss:0.00896\tvalid-mlogloss:0.12646\n",
            "[208]\ttrain-mlogloss:0.00896\tvalid-mlogloss:0.12646\n",
            "[209]\ttrain-mlogloss:0.00895\tvalid-mlogloss:0.12647\n",
            "[210]\ttrain-mlogloss:0.00895\tvalid-mlogloss:0.12649\n",
            "[211]\ttrain-mlogloss:0.00895\tvalid-mlogloss:0.12650\n",
            "[212]\ttrain-mlogloss:0.00894\tvalid-mlogloss:0.12651\n",
            "[213]\ttrain-mlogloss:0.00894\tvalid-mlogloss:0.12651\n",
            "[214]\ttrain-mlogloss:0.00893\tvalid-mlogloss:0.12651\n",
            "[215]\ttrain-mlogloss:0.00893\tvalid-mlogloss:0.12652\n",
            "[216]\ttrain-mlogloss:0.00893\tvalid-mlogloss:0.12652\n",
            "[217]\ttrain-mlogloss:0.00892\tvalid-mlogloss:0.12652\n",
            "[218]\ttrain-mlogloss:0.00892\tvalid-mlogloss:0.12652\n",
            "[219]\ttrain-mlogloss:0.00892\tvalid-mlogloss:0.12651\n",
            "[220]\ttrain-mlogloss:0.00891\tvalid-mlogloss:0.12652\n",
            "[221]\ttrain-mlogloss:0.00891\tvalid-mlogloss:0.12652\n",
            "[222]\ttrain-mlogloss:0.00891\tvalid-mlogloss:0.12653\n",
            "[223]\ttrain-mlogloss:0.00890\tvalid-mlogloss:0.12653\n",
            "[224]\ttrain-mlogloss:0.00890\tvalid-mlogloss:0.12654\n",
            "[225]\ttrain-mlogloss:0.00890\tvalid-mlogloss:0.12654\n",
            "[226]\ttrain-mlogloss:0.00889\tvalid-mlogloss:0.12656\n",
            "[227]\ttrain-mlogloss:0.00889\tvalid-mlogloss:0.12657\n",
            "[228]\ttrain-mlogloss:0.00889\tvalid-mlogloss:0.12658\n",
            "[229]\ttrain-mlogloss:0.00888\tvalid-mlogloss:0.12658\n",
            "[230]\ttrain-mlogloss:0.00888\tvalid-mlogloss:0.12658\n",
            "[231]\ttrain-mlogloss:0.00888\tvalid-mlogloss:0.12657\n",
            "[232]\ttrain-mlogloss:0.00888\tvalid-mlogloss:0.12659\n",
            "[233]\ttrain-mlogloss:0.00887\tvalid-mlogloss:0.12659\n",
            "[234]\ttrain-mlogloss:0.00887\tvalid-mlogloss:0.12660\n",
            "[235]\ttrain-mlogloss:0.00887\tvalid-mlogloss:0.12661\n",
            "[236]\ttrain-mlogloss:0.00886\tvalid-mlogloss:0.12662\n",
            "[237]\ttrain-mlogloss:0.00886\tvalid-mlogloss:0.12663\n",
            "[238]\ttrain-mlogloss:0.00886\tvalid-mlogloss:0.12663\n",
            "[239]\ttrain-mlogloss:0.00886\tvalid-mlogloss:0.12663\n",
            "[240]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.12665\n",
            "[241]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.12666\n",
            "[242]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.12667\n",
            "[243]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.12667\n",
            "[244]\ttrain-mlogloss:0.00884\tvalid-mlogloss:0.12669\n",
            "[245]\ttrain-mlogloss:0.00884\tvalid-mlogloss:0.12671\n",
            "[246]\ttrain-mlogloss:0.00884\tvalid-mlogloss:0.12672\n",
            "[247]\ttrain-mlogloss:0.00884\tvalid-mlogloss:0.12673\n",
            "[248]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.12673\n",
            "[checkpoint] saved /content/drive/MyDrive/Stanford/CS229/Final Project/llama+udmp-densityclustering_synthetic cases/xgb_checkpoints/xgb_fold3_0250.json\n",
            "[249]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.12673\n",
            "[250]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.12673\n",
            "[251]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.12673\n",
            "[252]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.12674\n",
            "[253]\ttrain-mlogloss:0.00882\tvalid-mlogloss:0.12675\n",
            "[254]\ttrain-mlogloss:0.00882\tvalid-mlogloss:0.12676\n",
            "[255]\ttrain-mlogloss:0.00882\tvalid-mlogloss:0.12677\n",
            "[256]\ttrain-mlogloss:0.00882\tvalid-mlogloss:0.12678\n",
            "[257]\ttrain-mlogloss:0.00881\tvalid-mlogloss:0.12679\n",
            "[258]\ttrain-mlogloss:0.00881\tvalid-mlogloss:0.12679\n",
            "[259]\ttrain-mlogloss:0.00881\tvalid-mlogloss:0.12679\n",
            "[260]\ttrain-mlogloss:0.00881\tvalid-mlogloss:0.12680\n",
            "[261]\ttrain-mlogloss:0.00881\tvalid-mlogloss:0.12680\n",
            "[262]\ttrain-mlogloss:0.00880\tvalid-mlogloss:0.12680\n",
            "[263]\ttrain-mlogloss:0.00880\tvalid-mlogloss:0.12681\n",
            "[264]\ttrain-mlogloss:0.00880\tvalid-mlogloss:0.12682\n",
            "[265]\ttrain-mlogloss:0.00880\tvalid-mlogloss:0.12684\n",
            "[266]\ttrain-mlogloss:0.00880\tvalid-mlogloss:0.12685\n",
            "[267]\ttrain-mlogloss:0.00879\tvalid-mlogloss:0.12686\n",
            "[268]\ttrain-mlogloss:0.00879\tvalid-mlogloss:0.12686\n",
            "[269]\ttrain-mlogloss:0.00879\tvalid-mlogloss:0.12686\n",
            "[270]\ttrain-mlogloss:0.00879\tvalid-mlogloss:0.12686\n",
            "[271]\ttrain-mlogloss:0.00879\tvalid-mlogloss:0.12687\n",
            "[272]\ttrain-mlogloss:0.00879\tvalid-mlogloss:0.12687\n",
            "[273]\ttrain-mlogloss:0.00878\tvalid-mlogloss:0.12687\n",
            "[274]\ttrain-mlogloss:0.00878\tvalid-mlogloss:0.12688\n",
            "[275]\ttrain-mlogloss:0.00878\tvalid-mlogloss:0.12689\n",
            "[276]\ttrain-mlogloss:0.00878\tvalid-mlogloss:0.12690\n",
            "[277]\ttrain-mlogloss:0.00878\tvalid-mlogloss:0.12691\n",
            "[278]\ttrain-mlogloss:0.00877\tvalid-mlogloss:0.12693\n",
            "[279]\ttrain-mlogloss:0.00877\tvalid-mlogloss:0.12693\n",
            "[280]\ttrain-mlogloss:0.00877\tvalid-mlogloss:0.12693\n",
            "✅ Saved final model: /content/drive/MyDrive/Stanford/CS229/Final Project/llama+udmp-densityclustering_synthetic cases/xgb_checkpoints/xgb_fold3_final.json\n",
            "Fold 3 accuracy: 0.9864\n",
            "Best iteration (early stop): 180\n",
            "\n",
            "===== Fold 4 =====\n",
            "➡️  No checkpoint found; starting fresh.\n",
            "[0]\ttrain-mlogloss:5.86956\tvalid-mlogloss:5.96002\n",
            "[1]\ttrain-mlogloss:4.42229\tvalid-mlogloss:4.59414\n",
            "[2]\ttrain-mlogloss:3.15912\tvalid-mlogloss:3.40920\n",
            "[3]\ttrain-mlogloss:2.60050\tvalid-mlogloss:2.87895\n",
            "[4]\ttrain-mlogloss:2.23419\tvalid-mlogloss:2.53831\n",
            "[5]\ttrain-mlogloss:1.95394\tvalid-mlogloss:2.27833\n",
            "[6]\ttrain-mlogloss:1.72844\tvalid-mlogloss:2.06794\n",
            "[7]\ttrain-mlogloss:1.54151\tvalid-mlogloss:1.89305\n",
            "[8]\ttrain-mlogloss:1.38307\tvalid-mlogloss:1.74378\n",
            "[9]\ttrain-mlogloss:1.24662\tvalid-mlogloss:1.61493\n",
            "[10]\ttrain-mlogloss:1.12797\tvalid-mlogloss:1.50130\n",
            "[11]\ttrain-mlogloss:1.02384\tvalid-mlogloss:1.40067\n",
            "[12]\ttrain-mlogloss:0.93152\tvalid-mlogloss:1.31086\n",
            "[13]\ttrain-mlogloss:0.84931\tvalid-mlogloss:1.22985\n",
            "[14]\ttrain-mlogloss:0.77580\tvalid-mlogloss:1.15652\n",
            "[15]\ttrain-mlogloss:0.70960\tvalid-mlogloss:1.08981\n",
            "[16]\ttrain-mlogloss:0.64997\tvalid-mlogloss:1.02850\n",
            "[17]\ttrain-mlogloss:0.59600\tvalid-mlogloss:0.97212\n",
            "[18]\ttrain-mlogloss:0.54707\tvalid-mlogloss:0.92028\n",
            "[19]\ttrain-mlogloss:0.50273\tvalid-mlogloss:0.87225\n",
            "[20]\ttrain-mlogloss:0.46234\tvalid-mlogloss:0.82787\n",
            "[21]\ttrain-mlogloss:0.42557\tvalid-mlogloss:0.78677\n",
            "[22]\ttrain-mlogloss:0.39206\tvalid-mlogloss:0.74853\n",
            "[23]\ttrain-mlogloss:0.36146\tvalid-mlogloss:0.71295\n",
            "[24]\ttrain-mlogloss:0.33358\tvalid-mlogloss:0.67976\n",
            "[25]\ttrain-mlogloss:0.30810\tvalid-mlogloss:0.64859\n",
            "[26]\ttrain-mlogloss:0.28476\tvalid-mlogloss:0.61966\n",
            "[27]\ttrain-mlogloss:0.26333\tvalid-mlogloss:0.59249\n",
            "[28]\ttrain-mlogloss:0.24374\tvalid-mlogloss:0.56714\n",
            "[29]\ttrain-mlogloss:0.22579\tvalid-mlogloss:0.54327\n",
            "[30]\ttrain-mlogloss:0.20928\tvalid-mlogloss:0.52074\n",
            "[31]\ttrain-mlogloss:0.19416\tvalid-mlogloss:0.49971\n",
            "[32]\ttrain-mlogloss:0.18024\tvalid-mlogloss:0.47990\n",
            "[33]\ttrain-mlogloss:0.16749\tvalid-mlogloss:0.46128\n",
            "[34]\ttrain-mlogloss:0.15577\tvalid-mlogloss:0.44388\n",
            "[35]\ttrain-mlogloss:0.14494\tvalid-mlogloss:0.42733\n",
            "[36]\ttrain-mlogloss:0.13505\tvalid-mlogloss:0.41174\n",
            "[37]\ttrain-mlogloss:0.12595\tvalid-mlogloss:0.39721\n",
            "[38]\ttrain-mlogloss:0.11754\tvalid-mlogloss:0.38335\n",
            "[39]\ttrain-mlogloss:0.10981\tvalid-mlogloss:0.37028\n",
            "[40]\ttrain-mlogloss:0.10265\tvalid-mlogloss:0.35792\n",
            "[41]\ttrain-mlogloss:0.09608\tvalid-mlogloss:0.34630\n",
            "[42]\ttrain-mlogloss:0.09000\tvalid-mlogloss:0.33518\n",
            "[43]\ttrain-mlogloss:0.08440\tvalid-mlogloss:0.32472\n",
            "[44]\ttrain-mlogloss:0.07921\tvalid-mlogloss:0.31470\n",
            "[45]\ttrain-mlogloss:0.07443\tvalid-mlogloss:0.30538\n",
            "[46]\ttrain-mlogloss:0.07000\tvalid-mlogloss:0.29640\n",
            "[47]\ttrain-mlogloss:0.06591\tvalid-mlogloss:0.28798\n",
            "[48]\ttrain-mlogloss:0.06213\tvalid-mlogloss:0.27992\n",
            "[49]\ttrain-mlogloss:0.05863\tvalid-mlogloss:0.27230\n",
            "[50]\ttrain-mlogloss:0.05539\tvalid-mlogloss:0.26511\n",
            "[51]\ttrain-mlogloss:0.05240\tvalid-mlogloss:0.25832\n",
            "[52]\ttrain-mlogloss:0.04963\tvalid-mlogloss:0.25188\n",
            "[53]\ttrain-mlogloss:0.04707\tvalid-mlogloss:0.24574\n",
            "[54]\ttrain-mlogloss:0.04469\tvalid-mlogloss:0.23987\n",
            "[55]\ttrain-mlogloss:0.04249\tvalid-mlogloss:0.23434\n",
            "[56]\ttrain-mlogloss:0.04045\tvalid-mlogloss:0.22904\n",
            "[57]\ttrain-mlogloss:0.03856\tvalid-mlogloss:0.22404\n",
            "[58]\ttrain-mlogloss:0.03679\tvalid-mlogloss:0.21925\n",
            "[59]\ttrain-mlogloss:0.03514\tvalid-mlogloss:0.21468\n",
            "[60]\ttrain-mlogloss:0.03360\tvalid-mlogloss:0.21029\n",
            "[61]\ttrain-mlogloss:0.03217\tvalid-mlogloss:0.20624\n",
            "[62]\ttrain-mlogloss:0.03083\tvalid-mlogloss:0.20233\n",
            "[63]\ttrain-mlogloss:0.02959\tvalid-mlogloss:0.19858\n",
            "[64]\ttrain-mlogloss:0.02841\tvalid-mlogloss:0.19499\n",
            "[65]\ttrain-mlogloss:0.02731\tvalid-mlogloss:0.19154\n",
            "[66]\ttrain-mlogloss:0.02626\tvalid-mlogloss:0.18819\n",
            "[67]\ttrain-mlogloss:0.02529\tvalid-mlogloss:0.18506\n",
            "[68]\ttrain-mlogloss:0.02437\tvalid-mlogloss:0.18199\n",
            "[69]\ttrain-mlogloss:0.02351\tvalid-mlogloss:0.17911\n",
            "[70]\ttrain-mlogloss:0.02269\tvalid-mlogloss:0.17635\n",
            "[71]\ttrain-mlogloss:0.02193\tvalid-mlogloss:0.17370\n",
            "[72]\ttrain-mlogloss:0.02121\tvalid-mlogloss:0.17119\n",
            "[73]\ttrain-mlogloss:0.02053\tvalid-mlogloss:0.16876\n",
            "[74]\ttrain-mlogloss:0.01989\tvalid-mlogloss:0.16639\n",
            "[75]\ttrain-mlogloss:0.01929\tvalid-mlogloss:0.16412\n",
            "[76]\ttrain-mlogloss:0.01871\tvalid-mlogloss:0.16204\n",
            "[77]\ttrain-mlogloss:0.01818\tvalid-mlogloss:0.16006\n",
            "[78]\ttrain-mlogloss:0.01767\tvalid-mlogloss:0.15810\n",
            "[79]\ttrain-mlogloss:0.01719\tvalid-mlogloss:0.15626\n",
            "[80]\ttrain-mlogloss:0.01674\tvalid-mlogloss:0.15446\n",
            "[81]\ttrain-mlogloss:0.01631\tvalid-mlogloss:0.15278\n",
            "[82]\ttrain-mlogloss:0.01591\tvalid-mlogloss:0.15118\n",
            "[83]\ttrain-mlogloss:0.01553\tvalid-mlogloss:0.14967\n",
            "[84]\ttrain-mlogloss:0.01517\tvalid-mlogloss:0.14825\n",
            "[85]\ttrain-mlogloss:0.01483\tvalid-mlogloss:0.14691\n",
            "[86]\ttrain-mlogloss:0.01450\tvalid-mlogloss:0.14565\n",
            "[87]\ttrain-mlogloss:0.01420\tvalid-mlogloss:0.14446\n",
            "[88]\ttrain-mlogloss:0.01392\tvalid-mlogloss:0.14333\n",
            "[89]\ttrain-mlogloss:0.01365\tvalid-mlogloss:0.14230\n",
            "[90]\ttrain-mlogloss:0.01340\tvalid-mlogloss:0.14125\n",
            "[91]\ttrain-mlogloss:0.01317\tvalid-mlogloss:0.14023\n",
            "[92]\ttrain-mlogloss:0.01294\tvalid-mlogloss:0.13930\n",
            "[93]\ttrain-mlogloss:0.01273\tvalid-mlogloss:0.13845\n",
            "[94]\ttrain-mlogloss:0.01253\tvalid-mlogloss:0.13765\n",
            "[95]\ttrain-mlogloss:0.01234\tvalid-mlogloss:0.13692\n",
            "[96]\ttrain-mlogloss:0.01217\tvalid-mlogloss:0.13625\n",
            "[97]\ttrain-mlogloss:0.01200\tvalid-mlogloss:0.13564\n",
            "[98]\ttrain-mlogloss:0.01185\tvalid-mlogloss:0.13504\n",
            "[99]\ttrain-mlogloss:0.01171\tvalid-mlogloss:0.13447\n",
            "[100]\ttrain-mlogloss:0.01158\tvalid-mlogloss:0.13394\n",
            "[101]\ttrain-mlogloss:0.01146\tvalid-mlogloss:0.13346\n",
            "[102]\ttrain-mlogloss:0.01134\tvalid-mlogloss:0.13299\n",
            "[103]\ttrain-mlogloss:0.01123\tvalid-mlogloss:0.13257\n",
            "[104]\ttrain-mlogloss:0.01113\tvalid-mlogloss:0.13216\n",
            "[105]\ttrain-mlogloss:0.01103\tvalid-mlogloss:0.13179\n",
            "[106]\ttrain-mlogloss:0.01094\tvalid-mlogloss:0.13146\n",
            "[107]\ttrain-mlogloss:0.01086\tvalid-mlogloss:0.13112\n",
            "[108]\ttrain-mlogloss:0.01078\tvalid-mlogloss:0.13081\n",
            "[109]\ttrain-mlogloss:0.01071\tvalid-mlogloss:0.13052\n",
            "[110]\ttrain-mlogloss:0.01064\tvalid-mlogloss:0.13028\n",
            "[111]\ttrain-mlogloss:0.01057\tvalid-mlogloss:0.13010\n",
            "[112]\ttrain-mlogloss:0.01051\tvalid-mlogloss:0.12989\n",
            "[113]\ttrain-mlogloss:0.01045\tvalid-mlogloss:0.12969\n",
            "[114]\ttrain-mlogloss:0.01039\tvalid-mlogloss:0.12948\n",
            "[115]\ttrain-mlogloss:0.01034\tvalid-mlogloss:0.12932\n",
            "[116]\ttrain-mlogloss:0.01029\tvalid-mlogloss:0.12912\n",
            "[117]\ttrain-mlogloss:0.01024\tvalid-mlogloss:0.12896\n",
            "[118]\ttrain-mlogloss:0.01019\tvalid-mlogloss:0.12880\n",
            "[119]\ttrain-mlogloss:0.01015\tvalid-mlogloss:0.12868\n",
            "[120]\ttrain-mlogloss:0.01011\tvalid-mlogloss:0.12856\n",
            "[121]\ttrain-mlogloss:0.01007\tvalid-mlogloss:0.12844\n",
            "[122]\ttrain-mlogloss:0.01003\tvalid-mlogloss:0.12830\n",
            "[123]\ttrain-mlogloss:0.01000\tvalid-mlogloss:0.12821\n",
            "[124]\ttrain-mlogloss:0.00996\tvalid-mlogloss:0.12812\n",
            "[125]\ttrain-mlogloss:0.00993\tvalid-mlogloss:0.12803\n",
            "[126]\ttrain-mlogloss:0.00990\tvalid-mlogloss:0.12794\n",
            "[127]\ttrain-mlogloss:0.00987\tvalid-mlogloss:0.12787\n",
            "[128]\ttrain-mlogloss:0.00984\tvalid-mlogloss:0.12778\n",
            "[129]\ttrain-mlogloss:0.00981\tvalid-mlogloss:0.12771\n",
            "[130]\ttrain-mlogloss:0.00979\tvalid-mlogloss:0.12762\n",
            "[131]\ttrain-mlogloss:0.00976\tvalid-mlogloss:0.12755\n",
            "[132]\ttrain-mlogloss:0.00974\tvalid-mlogloss:0.12749\n",
            "[133]\ttrain-mlogloss:0.00971\tvalid-mlogloss:0.12739\n",
            "[134]\ttrain-mlogloss:0.00969\tvalid-mlogloss:0.12733\n",
            "[135]\ttrain-mlogloss:0.00967\tvalid-mlogloss:0.12729\n",
            "[136]\ttrain-mlogloss:0.00964\tvalid-mlogloss:0.12723\n",
            "[137]\ttrain-mlogloss:0.00962\tvalid-mlogloss:0.12718\n",
            "[138]\ttrain-mlogloss:0.00960\tvalid-mlogloss:0.12714\n",
            "[139]\ttrain-mlogloss:0.00958\tvalid-mlogloss:0.12710\n",
            "[140]\ttrain-mlogloss:0.00957\tvalid-mlogloss:0.12707\n",
            "[141]\ttrain-mlogloss:0.00955\tvalid-mlogloss:0.12701\n",
            "[142]\ttrain-mlogloss:0.00953\tvalid-mlogloss:0.12698\n",
            "[143]\ttrain-mlogloss:0.00951\tvalid-mlogloss:0.12694\n",
            "[144]\ttrain-mlogloss:0.00950\tvalid-mlogloss:0.12691\n",
            "[145]\ttrain-mlogloss:0.00948\tvalid-mlogloss:0.12688\n",
            "[146]\ttrain-mlogloss:0.00946\tvalid-mlogloss:0.12685\n",
            "[147]\ttrain-mlogloss:0.00945\tvalid-mlogloss:0.12684\n",
            "[148]\ttrain-mlogloss:0.00943\tvalid-mlogloss:0.12683\n",
            "[149]\ttrain-mlogloss:0.00942\tvalid-mlogloss:0.12679\n",
            "[150]\ttrain-mlogloss:0.00941\tvalid-mlogloss:0.12677\n",
            "[151]\ttrain-mlogloss:0.00939\tvalid-mlogloss:0.12674\n",
            "[152]\ttrain-mlogloss:0.00938\tvalid-mlogloss:0.12673\n",
            "[153]\ttrain-mlogloss:0.00937\tvalid-mlogloss:0.12670\n",
            "[154]\ttrain-mlogloss:0.00935\tvalid-mlogloss:0.12670\n",
            "[155]\ttrain-mlogloss:0.00934\tvalid-mlogloss:0.12668\n",
            "[156]\ttrain-mlogloss:0.00933\tvalid-mlogloss:0.12668\n",
            "[157]\ttrain-mlogloss:0.00932\tvalid-mlogloss:0.12667\n",
            "[158]\ttrain-mlogloss:0.00931\tvalid-mlogloss:0.12664\n",
            "[159]\ttrain-mlogloss:0.00930\tvalid-mlogloss:0.12663\n",
            "[160]\ttrain-mlogloss:0.00929\tvalid-mlogloss:0.12663\n",
            "[161]\ttrain-mlogloss:0.00927\tvalid-mlogloss:0.12661\n",
            "[162]\ttrain-mlogloss:0.00926\tvalid-mlogloss:0.12659\n",
            "[163]\ttrain-mlogloss:0.00925\tvalid-mlogloss:0.12658\n",
            "[164]\ttrain-mlogloss:0.00924\tvalid-mlogloss:0.12656\n",
            "[165]\ttrain-mlogloss:0.00924\tvalid-mlogloss:0.12655\n",
            "[166]\ttrain-mlogloss:0.00923\tvalid-mlogloss:0.12655\n",
            "[167]\ttrain-mlogloss:0.00922\tvalid-mlogloss:0.12654\n",
            "[168]\ttrain-mlogloss:0.00921\tvalid-mlogloss:0.12654\n",
            "[169]\ttrain-mlogloss:0.00920\tvalid-mlogloss:0.12653\n",
            "[170]\ttrain-mlogloss:0.00919\tvalid-mlogloss:0.12652\n",
            "[171]\ttrain-mlogloss:0.00918\tvalid-mlogloss:0.12651\n",
            "[172]\ttrain-mlogloss:0.00917\tvalid-mlogloss:0.12651\n",
            "[173]\ttrain-mlogloss:0.00917\tvalid-mlogloss:0.12650\n",
            "[174]\ttrain-mlogloss:0.00916\tvalid-mlogloss:0.12650\n",
            "[175]\ttrain-mlogloss:0.00915\tvalid-mlogloss:0.12649\n",
            "[176]\ttrain-mlogloss:0.00914\tvalid-mlogloss:0.12649\n",
            "[177]\ttrain-mlogloss:0.00914\tvalid-mlogloss:0.12648\n",
            "[178]\ttrain-mlogloss:0.00913\tvalid-mlogloss:0.12647\n",
            "[179]\ttrain-mlogloss:0.00912\tvalid-mlogloss:0.12647\n",
            "[180]\ttrain-mlogloss:0.00912\tvalid-mlogloss:0.12647\n",
            "[181]\ttrain-mlogloss:0.00911\tvalid-mlogloss:0.12648\n",
            "[182]\ttrain-mlogloss:0.00910\tvalid-mlogloss:0.12649\n",
            "[183]\ttrain-mlogloss:0.00910\tvalid-mlogloss:0.12648\n",
            "[184]\ttrain-mlogloss:0.00909\tvalid-mlogloss:0.12646\n",
            "[185]\ttrain-mlogloss:0.00908\tvalid-mlogloss:0.12647\n",
            "[186]\ttrain-mlogloss:0.00908\tvalid-mlogloss:0.12647\n",
            "[187]\ttrain-mlogloss:0.00907\tvalid-mlogloss:0.12645\n",
            "[188]\ttrain-mlogloss:0.00907\tvalid-mlogloss:0.12644\n",
            "[189]\ttrain-mlogloss:0.00906\tvalid-mlogloss:0.12643\n",
            "[190]\ttrain-mlogloss:0.00906\tvalid-mlogloss:0.12641\n",
            "[191]\ttrain-mlogloss:0.00905\tvalid-mlogloss:0.12642\n",
            "[192]\ttrain-mlogloss:0.00904\tvalid-mlogloss:0.12643\n",
            "[193]\ttrain-mlogloss:0.00904\tvalid-mlogloss:0.12641\n",
            "[194]\ttrain-mlogloss:0.00903\tvalid-mlogloss:0.12641\n",
            "[195]\ttrain-mlogloss:0.00903\tvalid-mlogloss:0.12640\n",
            "[196]\ttrain-mlogloss:0.00902\tvalid-mlogloss:0.12640\n",
            "[197]\ttrain-mlogloss:0.00902\tvalid-mlogloss:0.12640\n",
            "[198]\ttrain-mlogloss:0.00901\tvalid-mlogloss:0.12638\n",
            "[199]\ttrain-mlogloss:0.00901\tvalid-mlogloss:0.12640\n",
            "[200]\ttrain-mlogloss:0.00901\tvalid-mlogloss:0.12639\n",
            "[201]\ttrain-mlogloss:0.00900\tvalid-mlogloss:0.12641\n",
            "[202]\ttrain-mlogloss:0.00900\tvalid-mlogloss:0.12640\n",
            "[203]\ttrain-mlogloss:0.00899\tvalid-mlogloss:0.12641\n",
            "[204]\ttrain-mlogloss:0.00899\tvalid-mlogloss:0.12642\n",
            "[205]\ttrain-mlogloss:0.00898\tvalid-mlogloss:0.12641\n",
            "[206]\ttrain-mlogloss:0.00898\tvalid-mlogloss:0.12642\n",
            "[207]\ttrain-mlogloss:0.00897\tvalid-mlogloss:0.12643\n",
            "[208]\ttrain-mlogloss:0.00897\tvalid-mlogloss:0.12644\n",
            "[209]\ttrain-mlogloss:0.00897\tvalid-mlogloss:0.12645\n",
            "[210]\ttrain-mlogloss:0.00896\tvalid-mlogloss:0.12644\n",
            "[211]\ttrain-mlogloss:0.00896\tvalid-mlogloss:0.12645\n",
            "[212]\ttrain-mlogloss:0.00895\tvalid-mlogloss:0.12645\n",
            "[213]\ttrain-mlogloss:0.00895\tvalid-mlogloss:0.12644\n",
            "[214]\ttrain-mlogloss:0.00895\tvalid-mlogloss:0.12644\n",
            "[215]\ttrain-mlogloss:0.00894\tvalid-mlogloss:0.12644\n",
            "[216]\ttrain-mlogloss:0.00894\tvalid-mlogloss:0.12644\n",
            "[217]\ttrain-mlogloss:0.00894\tvalid-mlogloss:0.12645\n",
            "[218]\ttrain-mlogloss:0.00893\tvalid-mlogloss:0.12647\n",
            "[219]\ttrain-mlogloss:0.00893\tvalid-mlogloss:0.12648\n",
            "[220]\ttrain-mlogloss:0.00893\tvalid-mlogloss:0.12648\n",
            "[221]\ttrain-mlogloss:0.00892\tvalid-mlogloss:0.12649\n",
            "[222]\ttrain-mlogloss:0.00892\tvalid-mlogloss:0.12648\n",
            "[223]\ttrain-mlogloss:0.00892\tvalid-mlogloss:0.12648\n",
            "[224]\ttrain-mlogloss:0.00891\tvalid-mlogloss:0.12648\n",
            "[225]\ttrain-mlogloss:0.00891\tvalid-mlogloss:0.12649\n",
            "[226]\ttrain-mlogloss:0.00891\tvalid-mlogloss:0.12649\n",
            "[227]\ttrain-mlogloss:0.00890\tvalid-mlogloss:0.12650\n",
            "[228]\ttrain-mlogloss:0.00890\tvalid-mlogloss:0.12651\n",
            "[229]\ttrain-mlogloss:0.00890\tvalid-mlogloss:0.12652\n",
            "[230]\ttrain-mlogloss:0.00889\tvalid-mlogloss:0.12651\n",
            "[231]\ttrain-mlogloss:0.00889\tvalid-mlogloss:0.12650\n",
            "[232]\ttrain-mlogloss:0.00889\tvalid-mlogloss:0.12650\n",
            "[233]\ttrain-mlogloss:0.00889\tvalid-mlogloss:0.12648\n",
            "[234]\ttrain-mlogloss:0.00888\tvalid-mlogloss:0.12650\n",
            "[235]\ttrain-mlogloss:0.00888\tvalid-mlogloss:0.12652\n",
            "[236]\ttrain-mlogloss:0.00888\tvalid-mlogloss:0.12653\n",
            "[237]\ttrain-mlogloss:0.00887\tvalid-mlogloss:0.12655\n",
            "[238]\ttrain-mlogloss:0.00887\tvalid-mlogloss:0.12655\n",
            "[239]\ttrain-mlogloss:0.00887\tvalid-mlogloss:0.12655\n",
            "[240]\ttrain-mlogloss:0.00887\tvalid-mlogloss:0.12656\n",
            "[241]\ttrain-mlogloss:0.00886\tvalid-mlogloss:0.12656\n",
            "[242]\ttrain-mlogloss:0.00886\tvalid-mlogloss:0.12657\n",
            "[243]\ttrain-mlogloss:0.00886\tvalid-mlogloss:0.12658\n",
            "[244]\ttrain-mlogloss:0.00886\tvalid-mlogloss:0.12659\n",
            "[245]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.12660\n",
            "[246]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.12661\n",
            "[247]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.12661\n",
            "[248]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.12662\n",
            "[checkpoint] saved /content/drive/MyDrive/Stanford/CS229/Final Project/llama+udmp-densityclustering_synthetic cases/xgb_checkpoints/xgb_fold4_0250.json\n",
            "[249]\ttrain-mlogloss:0.00884\tvalid-mlogloss:0.12663\n",
            "[250]\ttrain-mlogloss:0.00884\tvalid-mlogloss:0.12663\n",
            "[251]\ttrain-mlogloss:0.00884\tvalid-mlogloss:0.12663\n",
            "[252]\ttrain-mlogloss:0.00884\tvalid-mlogloss:0.12665\n",
            "[253]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.12665\n",
            "[254]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.12666\n",
            "[255]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.12667\n",
            "[256]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.12667\n",
            "[257]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.12669\n",
            "[258]\ttrain-mlogloss:0.00882\tvalid-mlogloss:0.12671\n",
            "[259]\ttrain-mlogloss:0.00882\tvalid-mlogloss:0.12670\n",
            "[260]\ttrain-mlogloss:0.00882\tvalid-mlogloss:0.12670\n",
            "[261]\ttrain-mlogloss:0.00882\tvalid-mlogloss:0.12672\n",
            "[262]\ttrain-mlogloss:0.00881\tvalid-mlogloss:0.12672\n",
            "[263]\ttrain-mlogloss:0.00881\tvalid-mlogloss:0.12672\n",
            "[264]\ttrain-mlogloss:0.00881\tvalid-mlogloss:0.12672\n",
            "[265]\ttrain-mlogloss:0.00881\tvalid-mlogloss:0.12673\n",
            "[266]\ttrain-mlogloss:0.00881\tvalid-mlogloss:0.12672\n",
            "[267]\ttrain-mlogloss:0.00881\tvalid-mlogloss:0.12670\n",
            "[268]\ttrain-mlogloss:0.00880\tvalid-mlogloss:0.12671\n",
            "[269]\ttrain-mlogloss:0.00880\tvalid-mlogloss:0.12671\n",
            "[270]\ttrain-mlogloss:0.00880\tvalid-mlogloss:0.12671\n",
            "[271]\ttrain-mlogloss:0.00880\tvalid-mlogloss:0.12671\n",
            "[272]\ttrain-mlogloss:0.00880\tvalid-mlogloss:0.12671\n",
            "[273]\ttrain-mlogloss:0.00879\tvalid-mlogloss:0.12671\n",
            "[274]\ttrain-mlogloss:0.00879\tvalid-mlogloss:0.12672\n",
            "[275]\ttrain-mlogloss:0.00879\tvalid-mlogloss:0.12674\n",
            "[276]\ttrain-mlogloss:0.00879\tvalid-mlogloss:0.12674\n",
            "[277]\ttrain-mlogloss:0.00879\tvalid-mlogloss:0.12675\n",
            "[278]\ttrain-mlogloss:0.00878\tvalid-mlogloss:0.12677\n",
            "[279]\ttrain-mlogloss:0.00878\tvalid-mlogloss:0.12676\n",
            "[280]\ttrain-mlogloss:0.00878\tvalid-mlogloss:0.12676\n",
            "[281]\ttrain-mlogloss:0.00878\tvalid-mlogloss:0.12677\n",
            "[282]\ttrain-mlogloss:0.00878\tvalid-mlogloss:0.12676\n",
            "[283]\ttrain-mlogloss:0.00878\tvalid-mlogloss:0.12677\n",
            "[284]\ttrain-mlogloss:0.00877\tvalid-mlogloss:0.12676\n",
            "[285]\ttrain-mlogloss:0.00877\tvalid-mlogloss:0.12677\n",
            "[286]\ttrain-mlogloss:0.00877\tvalid-mlogloss:0.12678\n",
            "[287]\ttrain-mlogloss:0.00877\tvalid-mlogloss:0.12679\n",
            "[288]\ttrain-mlogloss:0.00877\tvalid-mlogloss:0.12679\n",
            "[289]\ttrain-mlogloss:0.00877\tvalid-mlogloss:0.12681\n",
            "[290]\ttrain-mlogloss:0.00876\tvalid-mlogloss:0.12681\n",
            "[291]\ttrain-mlogloss:0.00876\tvalid-mlogloss:0.12681\n",
            "[292]\ttrain-mlogloss:0.00876\tvalid-mlogloss:0.12682\n",
            "[293]\ttrain-mlogloss:0.00876\tvalid-mlogloss:0.12682\n",
            "[294]\ttrain-mlogloss:0.00876\tvalid-mlogloss:0.12683\n",
            "[295]\ttrain-mlogloss:0.00876\tvalid-mlogloss:0.12683\n",
            "[296]\ttrain-mlogloss:0.00876\tvalid-mlogloss:0.12683\n",
            "[297]\ttrain-mlogloss:0.00875\tvalid-mlogloss:0.12683\n",
            "[298]\ttrain-mlogloss:0.00875\tvalid-mlogloss:0.12683\n",
            "✅ Saved final model: /content/drive/MyDrive/Stanford/CS229/Final Project/llama+udmp-densityclustering_synthetic cases/xgb_checkpoints/xgb_fold4_final.json\n",
            "Fold 4 accuracy: 0.9863\n",
            "Best iteration (early stop): 198\n",
            "\n",
            "===== Fold 5 =====\n",
            "➡️  No checkpoint found; starting fresh.\n",
            "[0]\ttrain-mlogloss:5.88000\tvalid-mlogloss:5.95986\n",
            "[1]\ttrain-mlogloss:4.43603\tvalid-mlogloss:4.58074\n",
            "[2]\ttrain-mlogloss:3.16695\tvalid-mlogloss:3.38430\n",
            "[3]\ttrain-mlogloss:2.60431\tvalid-mlogloss:2.85343\n",
            "[4]\ttrain-mlogloss:2.23554\tvalid-mlogloss:2.51238\n",
            "[5]\ttrain-mlogloss:1.95410\tvalid-mlogloss:2.25281\n",
            "[6]\ttrain-mlogloss:1.72786\tvalid-mlogloss:2.04250\n",
            "[7]\ttrain-mlogloss:1.54084\tvalid-mlogloss:1.86737\n",
            "[8]\ttrain-mlogloss:1.38217\tvalid-mlogloss:1.71761\n",
            "[9]\ttrain-mlogloss:1.24595\tvalid-mlogloss:1.58831\n",
            "[10]\ttrain-mlogloss:1.12737\tvalid-mlogloss:1.47599\n",
            "[11]\ttrain-mlogloss:1.02303\tvalid-mlogloss:1.37645\n",
            "[12]\ttrain-mlogloss:0.93063\tvalid-mlogloss:1.28702\n",
            "[13]\ttrain-mlogloss:0.84842\tvalid-mlogloss:1.20629\n",
            "[14]\ttrain-mlogloss:0.77491\tvalid-mlogloss:1.13329\n",
            "[15]\ttrain-mlogloss:0.70871\tvalid-mlogloss:1.06667\n",
            "[16]\ttrain-mlogloss:0.64916\tvalid-mlogloss:1.00574\n",
            "[17]\ttrain-mlogloss:0.59524\tvalid-mlogloss:0.95006\n",
            "[18]\ttrain-mlogloss:0.54642\tvalid-mlogloss:0.89862\n",
            "[19]\ttrain-mlogloss:0.50205\tvalid-mlogloss:0.85094\n",
            "[20]\ttrain-mlogloss:0.46170\tvalid-mlogloss:0.80709\n",
            "[21]\ttrain-mlogloss:0.42499\tvalid-mlogloss:0.76629\n",
            "[22]\ttrain-mlogloss:0.39154\tvalid-mlogloss:0.72842\n",
            "[23]\ttrain-mlogloss:0.36102\tvalid-mlogloss:0.69315\n",
            "[24]\ttrain-mlogloss:0.33314\tvalid-mlogloss:0.66017\n",
            "[25]\ttrain-mlogloss:0.30767\tvalid-mlogloss:0.62956\n",
            "[26]\ttrain-mlogloss:0.28433\tvalid-mlogloss:0.60092\n",
            "[27]\ttrain-mlogloss:0.26294\tvalid-mlogloss:0.57395\n",
            "[28]\ttrain-mlogloss:0.24334\tvalid-mlogloss:0.54888\n",
            "[29]\ttrain-mlogloss:0.22542\tvalid-mlogloss:0.52525\n",
            "[30]\ttrain-mlogloss:0.20897\tvalid-mlogloss:0.50344\n",
            "[31]\ttrain-mlogloss:0.19382\tvalid-mlogloss:0.48287\n",
            "[32]\ttrain-mlogloss:0.17992\tvalid-mlogloss:0.46339\n",
            "[33]\ttrain-mlogloss:0.16719\tvalid-mlogloss:0.44522\n",
            "[34]\ttrain-mlogloss:0.15551\tvalid-mlogloss:0.42805\n",
            "[35]\ttrain-mlogloss:0.14475\tvalid-mlogloss:0.41188\n",
            "[36]\ttrain-mlogloss:0.13485\tvalid-mlogloss:0.39666\n",
            "[37]\ttrain-mlogloss:0.12573\tvalid-mlogloss:0.38227\n",
            "[38]\ttrain-mlogloss:0.11736\tvalid-mlogloss:0.36885\n",
            "[39]\ttrain-mlogloss:0.10962\tvalid-mlogloss:0.35601\n",
            "[40]\ttrain-mlogloss:0.10250\tvalid-mlogloss:0.34387\n",
            "[41]\ttrain-mlogloss:0.09592\tvalid-mlogloss:0.33240\n",
            "[42]\ttrain-mlogloss:0.08987\tvalid-mlogloss:0.32169\n",
            "[43]\ttrain-mlogloss:0.08428\tvalid-mlogloss:0.31145\n",
            "[44]\ttrain-mlogloss:0.07911\tvalid-mlogloss:0.30175\n",
            "[45]\ttrain-mlogloss:0.07432\tvalid-mlogloss:0.29247\n",
            "[46]\ttrain-mlogloss:0.06993\tvalid-mlogloss:0.28373\n",
            "[47]\ttrain-mlogloss:0.06583\tvalid-mlogloss:0.27540\n",
            "[48]\ttrain-mlogloss:0.06205\tvalid-mlogloss:0.26757\n",
            "[49]\ttrain-mlogloss:0.05855\tvalid-mlogloss:0.26007\n",
            "[50]\ttrain-mlogloss:0.05533\tvalid-mlogloss:0.25306\n",
            "[51]\ttrain-mlogloss:0.05235\tvalid-mlogloss:0.24645\n",
            "[52]\ttrain-mlogloss:0.04958\tvalid-mlogloss:0.24011\n",
            "[53]\ttrain-mlogloss:0.04703\tvalid-mlogloss:0.23411\n",
            "[54]\ttrain-mlogloss:0.04464\tvalid-mlogloss:0.22835\n",
            "[55]\ttrain-mlogloss:0.04244\tvalid-mlogloss:0.22293\n",
            "[56]\ttrain-mlogloss:0.04039\tvalid-mlogloss:0.21787\n",
            "[57]\ttrain-mlogloss:0.03851\tvalid-mlogloss:0.21304\n",
            "[58]\ttrain-mlogloss:0.03674\tvalid-mlogloss:0.20843\n",
            "[59]\ttrain-mlogloss:0.03510\tvalid-mlogloss:0.20396\n",
            "[60]\ttrain-mlogloss:0.03357\tvalid-mlogloss:0.19972\n",
            "[61]\ttrain-mlogloss:0.03214\tvalid-mlogloss:0.19565\n",
            "[62]\ttrain-mlogloss:0.03080\tvalid-mlogloss:0.19177\n",
            "[63]\ttrain-mlogloss:0.02955\tvalid-mlogloss:0.18814\n",
            "[64]\ttrain-mlogloss:0.02838\tvalid-mlogloss:0.18462\n",
            "[65]\ttrain-mlogloss:0.02728\tvalid-mlogloss:0.18136\n",
            "[66]\ttrain-mlogloss:0.02625\tvalid-mlogloss:0.17817\n",
            "[67]\ttrain-mlogloss:0.02528\tvalid-mlogloss:0.17510\n",
            "[68]\ttrain-mlogloss:0.02438\tvalid-mlogloss:0.17215\n",
            "[69]\ttrain-mlogloss:0.02352\tvalid-mlogloss:0.16936\n",
            "[70]\ttrain-mlogloss:0.02271\tvalid-mlogloss:0.16670\n",
            "[71]\ttrain-mlogloss:0.02195\tvalid-mlogloss:0.16413\n",
            "[72]\ttrain-mlogloss:0.02123\tvalid-mlogloss:0.16169\n",
            "[73]\ttrain-mlogloss:0.02055\tvalid-mlogloss:0.15928\n",
            "[74]\ttrain-mlogloss:0.01991\tvalid-mlogloss:0.15704\n",
            "[75]\ttrain-mlogloss:0.01930\tvalid-mlogloss:0.15486\n",
            "[76]\ttrain-mlogloss:0.01873\tvalid-mlogloss:0.15280\n",
            "[77]\ttrain-mlogloss:0.01819\tvalid-mlogloss:0.15080\n",
            "[78]\ttrain-mlogloss:0.01768\tvalid-mlogloss:0.14891\n",
            "[79]\ttrain-mlogloss:0.01720\tvalid-mlogloss:0.14717\n",
            "[80]\ttrain-mlogloss:0.01675\tvalid-mlogloss:0.14548\n",
            "[81]\ttrain-mlogloss:0.01632\tvalid-mlogloss:0.14387\n",
            "[82]\ttrain-mlogloss:0.01592\tvalid-mlogloss:0.14236\n",
            "[83]\ttrain-mlogloss:0.01554\tvalid-mlogloss:0.14093\n",
            "[84]\ttrain-mlogloss:0.01518\tvalid-mlogloss:0.13956\n",
            "[85]\ttrain-mlogloss:0.01485\tvalid-mlogloss:0.13830\n",
            "[86]\ttrain-mlogloss:0.01453\tvalid-mlogloss:0.13706\n",
            "[87]\ttrain-mlogloss:0.01423\tvalid-mlogloss:0.13590\n",
            "[88]\ttrain-mlogloss:0.01395\tvalid-mlogloss:0.13480\n",
            "[89]\ttrain-mlogloss:0.01368\tvalid-mlogloss:0.13376\n",
            "[90]\ttrain-mlogloss:0.01343\tvalid-mlogloss:0.13278\n",
            "[91]\ttrain-mlogloss:0.01319\tvalid-mlogloss:0.13187\n",
            "[92]\ttrain-mlogloss:0.01296\tvalid-mlogloss:0.13102\n",
            "[93]\ttrain-mlogloss:0.01275\tvalid-mlogloss:0.13017\n",
            "[94]\ttrain-mlogloss:0.01256\tvalid-mlogloss:0.12938\n",
            "[95]\ttrain-mlogloss:0.01237\tvalid-mlogloss:0.12864\n",
            "[96]\ttrain-mlogloss:0.01220\tvalid-mlogloss:0.12793\n",
            "[97]\ttrain-mlogloss:0.01203\tvalid-mlogloss:0.12729\n",
            "[98]\ttrain-mlogloss:0.01188\tvalid-mlogloss:0.12671\n",
            "[99]\ttrain-mlogloss:0.01174\tvalid-mlogloss:0.12616\n",
            "[100]\ttrain-mlogloss:0.01161\tvalid-mlogloss:0.12567\n",
            "[101]\ttrain-mlogloss:0.01149\tvalid-mlogloss:0.12521\n",
            "[102]\ttrain-mlogloss:0.01137\tvalid-mlogloss:0.12478\n",
            "[103]\ttrain-mlogloss:0.01126\tvalid-mlogloss:0.12439\n",
            "[104]\ttrain-mlogloss:0.01116\tvalid-mlogloss:0.12404\n",
            "[105]\ttrain-mlogloss:0.01106\tvalid-mlogloss:0.12371\n",
            "[106]\ttrain-mlogloss:0.01097\tvalid-mlogloss:0.12337\n",
            "[107]\ttrain-mlogloss:0.01089\tvalid-mlogloss:0.12306\n",
            "[108]\ttrain-mlogloss:0.01081\tvalid-mlogloss:0.12280\n",
            "[109]\ttrain-mlogloss:0.01073\tvalid-mlogloss:0.12256\n",
            "[110]\ttrain-mlogloss:0.01066\tvalid-mlogloss:0.12231\n",
            "[111]\ttrain-mlogloss:0.01059\tvalid-mlogloss:0.12209\n",
            "[112]\ttrain-mlogloss:0.01053\tvalid-mlogloss:0.12191\n",
            "[113]\ttrain-mlogloss:0.01047\tvalid-mlogloss:0.12173\n",
            "[114]\ttrain-mlogloss:0.01042\tvalid-mlogloss:0.12154\n",
            "[115]\ttrain-mlogloss:0.01037\tvalid-mlogloss:0.12137\n",
            "[116]\ttrain-mlogloss:0.01032\tvalid-mlogloss:0.12122\n",
            "[117]\ttrain-mlogloss:0.01027\tvalid-mlogloss:0.12106\n",
            "[118]\ttrain-mlogloss:0.01022\tvalid-mlogloss:0.12092\n",
            "[119]\ttrain-mlogloss:0.01018\tvalid-mlogloss:0.12078\n",
            "[120]\ttrain-mlogloss:0.01014\tvalid-mlogloss:0.12067\n",
            "[121]\ttrain-mlogloss:0.01010\tvalid-mlogloss:0.12058\n",
            "[122]\ttrain-mlogloss:0.01006\tvalid-mlogloss:0.12050\n",
            "[123]\ttrain-mlogloss:0.01003\tvalid-mlogloss:0.12044\n",
            "[124]\ttrain-mlogloss:0.00999\tvalid-mlogloss:0.12034\n",
            "[125]\ttrain-mlogloss:0.00996\tvalid-mlogloss:0.12027\n",
            "[126]\ttrain-mlogloss:0.00993\tvalid-mlogloss:0.12019\n",
            "[127]\ttrain-mlogloss:0.00990\tvalid-mlogloss:0.12012\n",
            "[128]\ttrain-mlogloss:0.00987\tvalid-mlogloss:0.12008\n",
            "[129]\ttrain-mlogloss:0.00984\tvalid-mlogloss:0.12002\n",
            "[130]\ttrain-mlogloss:0.00982\tvalid-mlogloss:0.11996\n",
            "[131]\ttrain-mlogloss:0.00979\tvalid-mlogloss:0.11990\n",
            "[132]\ttrain-mlogloss:0.00977\tvalid-mlogloss:0.11986\n",
            "[133]\ttrain-mlogloss:0.00974\tvalid-mlogloss:0.11981\n",
            "[134]\ttrain-mlogloss:0.00972\tvalid-mlogloss:0.11977\n",
            "[135]\ttrain-mlogloss:0.00969\tvalid-mlogloss:0.11972\n",
            "[136]\ttrain-mlogloss:0.00967\tvalid-mlogloss:0.11967\n",
            "[137]\ttrain-mlogloss:0.00965\tvalid-mlogloss:0.11964\n",
            "[138]\ttrain-mlogloss:0.00963\tvalid-mlogloss:0.11960\n",
            "[139]\ttrain-mlogloss:0.00961\tvalid-mlogloss:0.11957\n",
            "[140]\ttrain-mlogloss:0.00959\tvalid-mlogloss:0.11953\n",
            "[141]\ttrain-mlogloss:0.00957\tvalid-mlogloss:0.11951\n",
            "[142]\ttrain-mlogloss:0.00956\tvalid-mlogloss:0.11949\n",
            "[143]\ttrain-mlogloss:0.00954\tvalid-mlogloss:0.11945\n",
            "[144]\ttrain-mlogloss:0.00952\tvalid-mlogloss:0.11942\n",
            "[145]\ttrain-mlogloss:0.00951\tvalid-mlogloss:0.11940\n",
            "[146]\ttrain-mlogloss:0.00949\tvalid-mlogloss:0.11937\n",
            "[147]\ttrain-mlogloss:0.00947\tvalid-mlogloss:0.11937\n",
            "[148]\ttrain-mlogloss:0.00946\tvalid-mlogloss:0.11934\n",
            "[149]\ttrain-mlogloss:0.00945\tvalid-mlogloss:0.11932\n",
            "[150]\ttrain-mlogloss:0.00943\tvalid-mlogloss:0.11932\n",
            "[151]\ttrain-mlogloss:0.00942\tvalid-mlogloss:0.11931\n",
            "[152]\ttrain-mlogloss:0.00941\tvalid-mlogloss:0.11930\n",
            "[153]\ttrain-mlogloss:0.00939\tvalid-mlogloss:0.11931\n",
            "[154]\ttrain-mlogloss:0.00938\tvalid-mlogloss:0.11927\n",
            "[155]\ttrain-mlogloss:0.00937\tvalid-mlogloss:0.11927\n",
            "[156]\ttrain-mlogloss:0.00936\tvalid-mlogloss:0.11925\n",
            "[157]\ttrain-mlogloss:0.00934\tvalid-mlogloss:0.11923\n",
            "[158]\ttrain-mlogloss:0.00933\tvalid-mlogloss:0.11922\n",
            "[159]\ttrain-mlogloss:0.00932\tvalid-mlogloss:0.11921\n",
            "[160]\ttrain-mlogloss:0.00931\tvalid-mlogloss:0.11920\n",
            "[161]\ttrain-mlogloss:0.00930\tvalid-mlogloss:0.11920\n",
            "[162]\ttrain-mlogloss:0.00929\tvalid-mlogloss:0.11919\n",
            "[163]\ttrain-mlogloss:0.00928\tvalid-mlogloss:0.11917\n",
            "[164]\ttrain-mlogloss:0.00927\tvalid-mlogloss:0.11919\n",
            "[165]\ttrain-mlogloss:0.00926\tvalid-mlogloss:0.11919\n",
            "[166]\ttrain-mlogloss:0.00925\tvalid-mlogloss:0.11919\n",
            "[167]\ttrain-mlogloss:0.00924\tvalid-mlogloss:0.11919\n",
            "[168]\ttrain-mlogloss:0.00923\tvalid-mlogloss:0.11918\n",
            "[169]\ttrain-mlogloss:0.00923\tvalid-mlogloss:0.11918\n",
            "[170]\ttrain-mlogloss:0.00922\tvalid-mlogloss:0.11919\n",
            "[171]\ttrain-mlogloss:0.00921\tvalid-mlogloss:0.11919\n",
            "[172]\ttrain-mlogloss:0.00920\tvalid-mlogloss:0.11920\n",
            "[173]\ttrain-mlogloss:0.00919\tvalid-mlogloss:0.11921\n",
            "[174]\ttrain-mlogloss:0.00918\tvalid-mlogloss:0.11921\n",
            "[175]\ttrain-mlogloss:0.00917\tvalid-mlogloss:0.11921\n",
            "[176]\ttrain-mlogloss:0.00917\tvalid-mlogloss:0.11920\n",
            "[177]\ttrain-mlogloss:0.00916\tvalid-mlogloss:0.11918\n",
            "[178]\ttrain-mlogloss:0.00915\tvalid-mlogloss:0.11918\n",
            "[179]\ttrain-mlogloss:0.00914\tvalid-mlogloss:0.11919\n",
            "[180]\ttrain-mlogloss:0.00914\tvalid-mlogloss:0.11917\n",
            "[181]\ttrain-mlogloss:0.00913\tvalid-mlogloss:0.11917\n",
            "[182]\ttrain-mlogloss:0.00912\tvalid-mlogloss:0.11920\n",
            "[183]\ttrain-mlogloss:0.00912\tvalid-mlogloss:0.11921\n",
            "[184]\ttrain-mlogloss:0.00911\tvalid-mlogloss:0.11921\n",
            "[185]\ttrain-mlogloss:0.00911\tvalid-mlogloss:0.11922\n",
            "[186]\ttrain-mlogloss:0.00910\tvalid-mlogloss:0.11923\n",
            "[187]\ttrain-mlogloss:0.00910\tvalid-mlogloss:0.11924\n",
            "[188]\ttrain-mlogloss:0.00909\tvalid-mlogloss:0.11925\n",
            "[189]\ttrain-mlogloss:0.00908\tvalid-mlogloss:0.11927\n",
            "[190]\ttrain-mlogloss:0.00908\tvalid-mlogloss:0.11928\n",
            "[191]\ttrain-mlogloss:0.00907\tvalid-mlogloss:0.11928\n",
            "[192]\ttrain-mlogloss:0.00907\tvalid-mlogloss:0.11929\n",
            "[193]\ttrain-mlogloss:0.00906\tvalid-mlogloss:0.11929\n",
            "[194]\ttrain-mlogloss:0.00905\tvalid-mlogloss:0.11929\n",
            "[195]\ttrain-mlogloss:0.00905\tvalid-mlogloss:0.11930\n",
            "[196]\ttrain-mlogloss:0.00904\tvalid-mlogloss:0.11931\n",
            "[197]\ttrain-mlogloss:0.00904\tvalid-mlogloss:0.11931\n",
            "[198]\ttrain-mlogloss:0.00904\tvalid-mlogloss:0.11930\n",
            "[199]\ttrain-mlogloss:0.00903\tvalid-mlogloss:0.11930\n",
            "[200]\ttrain-mlogloss:0.00903\tvalid-mlogloss:0.11931\n",
            "[201]\ttrain-mlogloss:0.00902\tvalid-mlogloss:0.11931\n",
            "[202]\ttrain-mlogloss:0.00902\tvalid-mlogloss:0.11932\n",
            "[203]\ttrain-mlogloss:0.00901\tvalid-mlogloss:0.11933\n",
            "[204]\ttrain-mlogloss:0.00901\tvalid-mlogloss:0.11934\n",
            "[205]\ttrain-mlogloss:0.00900\tvalid-mlogloss:0.11935\n",
            "[206]\ttrain-mlogloss:0.00900\tvalid-mlogloss:0.11935\n",
            "[207]\ttrain-mlogloss:0.00900\tvalid-mlogloss:0.11936\n",
            "[208]\ttrain-mlogloss:0.00899\tvalid-mlogloss:0.11936\n",
            "[209]\ttrain-mlogloss:0.00899\tvalid-mlogloss:0.11938\n",
            "[210]\ttrain-mlogloss:0.00898\tvalid-mlogloss:0.11940\n",
            "[211]\ttrain-mlogloss:0.00898\tvalid-mlogloss:0.11941\n",
            "[212]\ttrain-mlogloss:0.00898\tvalid-mlogloss:0.11941\n",
            "[213]\ttrain-mlogloss:0.00897\tvalid-mlogloss:0.11943\n",
            "[214]\ttrain-mlogloss:0.00897\tvalid-mlogloss:0.11943\n",
            "[215]\ttrain-mlogloss:0.00896\tvalid-mlogloss:0.11944\n",
            "[216]\ttrain-mlogloss:0.00896\tvalid-mlogloss:0.11943\n",
            "[217]\ttrain-mlogloss:0.00896\tvalid-mlogloss:0.11943\n",
            "[218]\ttrain-mlogloss:0.00895\tvalid-mlogloss:0.11945\n",
            "[219]\ttrain-mlogloss:0.00895\tvalid-mlogloss:0.11945\n",
            "[220]\ttrain-mlogloss:0.00895\tvalid-mlogloss:0.11946\n",
            "[221]\ttrain-mlogloss:0.00894\tvalid-mlogloss:0.11946\n",
            "[222]\ttrain-mlogloss:0.00894\tvalid-mlogloss:0.11947\n",
            "[223]\ttrain-mlogloss:0.00894\tvalid-mlogloss:0.11948\n",
            "[224]\ttrain-mlogloss:0.00893\tvalid-mlogloss:0.11949\n",
            "[225]\ttrain-mlogloss:0.00893\tvalid-mlogloss:0.11950\n",
            "[226]\ttrain-mlogloss:0.00893\tvalid-mlogloss:0.11950\n",
            "[227]\ttrain-mlogloss:0.00892\tvalid-mlogloss:0.11951\n",
            "[228]\ttrain-mlogloss:0.00892\tvalid-mlogloss:0.11952\n",
            "[229]\ttrain-mlogloss:0.00892\tvalid-mlogloss:0.11953\n",
            "[230]\ttrain-mlogloss:0.00892\tvalid-mlogloss:0.11953\n",
            "[231]\ttrain-mlogloss:0.00891\tvalid-mlogloss:0.11953\n",
            "[232]\ttrain-mlogloss:0.00891\tvalid-mlogloss:0.11953\n",
            "[233]\ttrain-mlogloss:0.00891\tvalid-mlogloss:0.11953\n",
            "[234]\ttrain-mlogloss:0.00890\tvalid-mlogloss:0.11953\n",
            "[235]\ttrain-mlogloss:0.00890\tvalid-mlogloss:0.11954\n",
            "[236]\ttrain-mlogloss:0.00890\tvalid-mlogloss:0.11954\n",
            "[237]\ttrain-mlogloss:0.00889\tvalid-mlogloss:0.11954\n",
            "[238]\ttrain-mlogloss:0.00889\tvalid-mlogloss:0.11955\n",
            "[239]\ttrain-mlogloss:0.00889\tvalid-mlogloss:0.11957\n",
            "[240]\ttrain-mlogloss:0.00889\tvalid-mlogloss:0.11958\n",
            "[241]\ttrain-mlogloss:0.00888\tvalid-mlogloss:0.11958\n",
            "[242]\ttrain-mlogloss:0.00888\tvalid-mlogloss:0.11958\n",
            "[243]\ttrain-mlogloss:0.00888\tvalid-mlogloss:0.11960\n",
            "[244]\ttrain-mlogloss:0.00888\tvalid-mlogloss:0.11960\n",
            "[245]\ttrain-mlogloss:0.00887\tvalid-mlogloss:0.11961\n",
            "[246]\ttrain-mlogloss:0.00887\tvalid-mlogloss:0.11961\n",
            "[247]\ttrain-mlogloss:0.00887\tvalid-mlogloss:0.11963\n",
            "[248]\ttrain-mlogloss:0.00887\tvalid-mlogloss:0.11963\n",
            "[checkpoint] saved /content/drive/MyDrive/Stanford/CS229/Final Project/llama+udmp-densityclustering_synthetic cases/xgb_checkpoints/xgb_fold5_0250.json\n",
            "[249]\ttrain-mlogloss:0.00886\tvalid-mlogloss:0.11964\n",
            "[250]\ttrain-mlogloss:0.00886\tvalid-mlogloss:0.11966\n",
            "[251]\ttrain-mlogloss:0.00886\tvalid-mlogloss:0.11967\n",
            "[252]\ttrain-mlogloss:0.00886\tvalid-mlogloss:0.11967\n",
            "[253]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.11967\n",
            "[254]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.11968\n",
            "[255]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.11969\n",
            "[256]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.11970\n",
            "[257]\ttrain-mlogloss:0.00885\tvalid-mlogloss:0.11971\n",
            "[258]\ttrain-mlogloss:0.00884\tvalid-mlogloss:0.11972\n",
            "[259]\ttrain-mlogloss:0.00884\tvalid-mlogloss:0.11972\n",
            "[260]\ttrain-mlogloss:0.00884\tvalid-mlogloss:0.11974\n",
            "[261]\ttrain-mlogloss:0.00884\tvalid-mlogloss:0.11974\n",
            "[262]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.11976\n",
            "[263]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.11977\n",
            "[264]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.11977\n",
            "[265]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.11977\n",
            "[266]\ttrain-mlogloss:0.00883\tvalid-mlogloss:0.11979\n",
            "[267]\ttrain-mlogloss:0.00882\tvalid-mlogloss:0.11980\n",
            "[268]\ttrain-mlogloss:0.00882\tvalid-mlogloss:0.11980\n",
            "[269]\ttrain-mlogloss:0.00882\tvalid-mlogloss:0.11980\n",
            "[270]\ttrain-mlogloss:0.00882\tvalid-mlogloss:0.11983\n",
            "[271]\ttrain-mlogloss:0.00882\tvalid-mlogloss:0.11984\n",
            "[272]\ttrain-mlogloss:0.00881\tvalid-mlogloss:0.11984\n",
            "[273]\ttrain-mlogloss:0.00881\tvalid-mlogloss:0.11985\n",
            "[274]\ttrain-mlogloss:0.00881\tvalid-mlogloss:0.11987\n",
            "[275]\ttrain-mlogloss:0.00881\tvalid-mlogloss:0.11989\n",
            "[276]\ttrain-mlogloss:0.00881\tvalid-mlogloss:0.11989\n",
            "[277]\ttrain-mlogloss:0.00881\tvalid-mlogloss:0.11990\n",
            "[278]\ttrain-mlogloss:0.00880\tvalid-mlogloss:0.11991\n",
            "[279]\ttrain-mlogloss:0.00880\tvalid-mlogloss:0.11993\n",
            "[280]\ttrain-mlogloss:0.00880\tvalid-mlogloss:0.11994\n",
            "✅ Saved final model: /content/drive/MyDrive/Stanford/CS229/Final Project/llama+udmp-densityclustering_synthetic cases/xgb_checkpoints/xgb_fold5_final.json\n",
            "Fold 5 accuracy: 0.9871\n",
            "Best iteration (early stop): 180\n",
            "\n",
            "Mean CV accuracy: 0.9867 ± 0.0003\n",
            "All checkpoints & final models in: /content/drive/MyDrive/Stanford/CS229/Final Project/llama+udmp-densityclustering_synthetic cases/xgb_checkpoints\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Testing Validation"
      ],
      "metadata": {
        "id": "x74nHip25lur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "SAVE_DIR = Path(\"/content/drive/MyDrive/Stanford/CS229/Final Project/llama+udmp-densityclustering_synthetic cases/xgb_checkpoints\")\n",
        "\n",
        "# find all final models\n",
        "final_models = sorted(SAVE_DIR.glob(\"xgb_fold*_final.json\"))\n",
        "print(f\"Found {len(final_models)} fold models\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_mgjYxhzXkt",
        "outputId": "4b3712f5-5af3-4f30-e37c-d4af186f589f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5 fold models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dval = xgb.DMatrix(X_test, label=y_test)"
      ],
      "metadata": {
        "id": "jHEWqDavP0v6"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = []\n",
        "for path in final_models:\n",
        "    booster = xgb.Booster()\n",
        "    booster.load_model(str(path))\n",
        "    best_it = getattr(booster, \"best_iteration\", None)\n",
        "    y_prob = booster.predict(dval, iteration_range=(0, best_it + 1) if best_it is not None else None)\n",
        "    probs.append(y_prob)\n",
        "\n",
        "# average across folds\n",
        "y_prob_mean = np.mean(probs, axis=0)\n",
        "y_pred = np.argmax(y_prob_mean, axis=1)"
      ],
      "metadata": {
        "id": "6FRNJMD1P5EW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(y_prob_mean)\n",
        "print(y_prob_mean.shape)\n",
        "print(y_pred.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1u1KvvKReje",
        "outputId": "c5e58e0d-9f78-4150-ee4d-0e9952c60283"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(34860, 1660)\n",
            "(34860,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "val_acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Final validation accuracy (ensemble of 5 folds): {val_acc:.4f}\")\n",
        "\n",
        "# (Optional) confusion matrix if you want to inspect per-class results\n",
        "# cm = confusion_matrix(y_val_enc, y_pred)\n",
        "# print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cjmu0JoRhGH",
        "outputId": "caabd38a-9013-4df1-8942-0df3277b360f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final validation accuracy (ensemble of 5 folds): 0.9898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 7: External Validation for PubMed and Clinical"
      ],
      "metadata": {
        "id": "EdVVpl3v5rpy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, top_k_accuracy_score\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# 7.1 Load external JSONL cohort\n",
        "# -------------------------------------------------------------------\n",
        "external_path = Path(\"/content/drive/MyDrive/Stanford/CS229/Final Project/llama+udmp-densityclustering_synthetic cases/test-cohort-llama-density-clusters-case-aggregated-vectors.jsonl\")\n",
        "\n",
        "def load_jsonl(path: Path) -> pd.DataFrame:\n",
        "    records = []\n",
        "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            records.append(json.loads(line))\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "df_ext = load_jsonl(external_path)\n",
        "print(\"External cohort shape:\", df_ext.shape)\n",
        "print(\"External columns:\", df_ext.columns.tolist())\n",
        "\n",
        "# Check case group distribution (assuming column 'case_group')\n",
        "print(\"\\ncase_group value counts:\")\n",
        "print(df_ext[\"case_group\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6A4EQ_3zXhk",
        "outputId": "3b1365eb-1562-4b33-dc58-1bcaba0e24d3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "External cohort shape: (208, 5)\n",
            "External columns: ['case_number', 'diagnosis', 'case_group', 'list_of_cluster_label_final', 'list_of_umap_vectors_100d']\n",
            "\n",
            "case_group value counts:\n",
            "case_group\n",
            "2    107\n",
            "1    101\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Keep only diagnoses that exist in training label space\n",
        "mask_known = df_ext[\"diagnosis\"].isin(le.classes_)\n",
        "if not mask_known.all():\n",
        "    n_dropped = (~mask_known).sum()\n",
        "    print(f\"⚠ Dropping {n_dropped} external samples with unseen diagnoses.\")\n",
        "    df_ext = df_ext[mask_known].reset_index(drop=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QSnaKjHzXeT",
        "outputId": "145721ab-0fa8-446f-89f3-45e354692dd1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠ Dropping 16 external samples with unseen diagnoses.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"External cohort after dropping unseen diagnoses:\", df_ext.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z5XuIeuWdae",
        "outputId": "52ea5210-fc47-48e2-82bd-8ce5aad751de"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "External cohort after dropping unseen diagnoses: (192, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_ext.columns.tolist())\n",
        "print(df_ext.iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNeffLgStJDL",
        "outputId": "a6fabb45-a0d7-4916-b435-eb52568f36ae"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['case_number', 'diagnosis', 'case_group', 'list_of_cluster_label_final', 'list_of_umap_vectors_100d']\n",
            "case_number                                                                    1\n",
            "diagnosis                           CHROMOSOME 22q11.2 DELETION SYNDROME, DISTAL\n",
            "case_group                                                                     2\n",
            "list_of_cluster_label_final              [20, 31, 108, 159, 303, 707, 931, 4592]\n",
            "list_of_umap_vectors_100d      [[0.019151507, 2.960222, -0.036849596, -0.5038...\n",
            "Name: 0, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_features_external(df: pd.DataFrame, cluster2idx: dict) -> csr_matrix:\n",
        "    n_samples = len(df)\n",
        "    n_clusters = len(cluster2idx)\n",
        "\n",
        "    # sparse multi-hot for clusters\n",
        "    X_clusters = lil_matrix((n_samples, n_clusters), dtype=np.float32)\n",
        "\n",
        "    # infer embedding dim from first row of list_of_umap_vectors_100d\n",
        "    first_vec = df.iloc[0][\"list_of_umap_vectors_100d\"]\n",
        "    arr = np.array(first_vec, dtype=np.float32)\n",
        "    if arr.ndim == 1:\n",
        "        embedding_dim = arr.shape[0]\n",
        "    elif arr.ndim == 2:\n",
        "        embedding_dim = arr.shape[1]\n",
        "    else:\n",
        "        raise ValueError(f\"Unexpected shape for list_of_umap_vectors_100d: {arr.shape}\")\n",
        "\n",
        "    X_embed = np.zeros((n_samples, embedding_dim), dtype=np.float32)\n",
        "    X_compl = np.ones((n_samples, 1), dtype=np.float32)  # set completeness = 1.0 for all\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        # multi-hot clusters from list_of_cluster_label_final\n",
        "        for cid in row[\"list_of_cluster_label_final\"]:\n",
        "            j = cluster2idx.get(cid)\n",
        "            if j is not None:       # ignore clusters never seen in training\n",
        "                X_clusters[i, j] = 1.0\n",
        "\n",
        "        # UMAP vectors (flat 100-d or list of 100-d vectors)\n",
        "        vec = np.array(row[\"list_of_umap_vectors_100d\"], dtype=np.float32)\n",
        "        if vec.ndim == 1:\n",
        "            mean_vec = vec\n",
        "        elif vec.ndim == 2:\n",
        "            mean_vec = vec.mean(axis=0)\n",
        "        else:\n",
        "            raise ValueError(f\"Row {i}: unexpected shape for list_of_umap_vectors_100d: {vec.shape}\")\n",
        "        X_embed[i] = mean_vec\n",
        "\n",
        "        # X_compl[i, 0] is already 1.0\n",
        "\n",
        "    X_clusters = X_clusters.tocsr()\n",
        "    X_dense = np.hstack([X_embed, X_compl])   # (n_samples, 100 + 1)\n",
        "    X_dense_sparse = csr_matrix(X_dense)\n",
        "\n",
        "    X = hstack([X_clusters, X_dense_sparse], format=\"csr\")\n",
        "    return X\n",
        "\n",
        "# Build external features\n",
        "X_ext = build_features_external(df_ext, cluster2idx)\n",
        "print(\"X_ext shape:\", X_ext.shape)\n",
        "\n",
        "# Encode labels\n",
        "y_ext = le.transform(df_ext[\"diagnosis\"])\n",
        "\n",
        "# DMatrix for XGBoost\n",
        "d_ext = xgb.DMatrix(X_ext, label=y_ext)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eixN3FujX1--",
        "outputId": "10811c1d-4651-4189-e473-aba55056a8db"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_ext shape: (192, 5463)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "probas_list = []\n",
        "\n",
        "for fold in range(1, actual_splits + 1):\n",
        "    model_path = SAVE_DIR / f\"xgb_fold{fold}_final.json\"\n",
        "    if not model_path.exists():\n",
        "        raise FileNotFoundError(f\"Model for fold {fold} not found: {model_path}\")\n",
        "    print(f\"Loading fold {fold} model from: {model_path}\")\n",
        "\n",
        "    booster = xgb.Booster()\n",
        "    booster.load_model(str(model_path))\n",
        "\n",
        "    y_proba_fold = booster.predict(d_ext)\n",
        "    probas_list.append(y_proba_fold)\n",
        "\n",
        "# Average probabilities across folds\n",
        "y_proba_ext = np.mean(probas_list, axis=0)   # (n_ext, NUM_CLASS)\n",
        "y_pred_ext  = np.argmax(y_proba_ext, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-aPhNwarX67d",
        "outputId": "dbcc5a69-8914-44e9-f8fa-486aa315c75c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading fold 1 model from: /content/drive/MyDrive/Stanford/CS229/Final Project/llama+udmp-densityclustering_synthetic cases/xgb_checkpoints/xgb_fold1_final.json\n",
            "Loading fold 2 model from: /content/drive/MyDrive/Stanford/CS229/Final Project/llama+udmp-densityclustering_synthetic cases/xgb_checkpoints/xgb_fold2_final.json\n",
            "Loading fold 3 model from: /content/drive/MyDrive/Stanford/CS229/Final Project/llama+udmp-densityclustering_synthetic cases/xgb_checkpoints/xgb_fold3_final.json\n",
            "Loading fold 4 model from: /content/drive/MyDrive/Stanford/CS229/Final Project/llama+udmp-densityclustering_synthetic cases/xgb_checkpoints/xgb_fold4_final.json\n",
            "Loading fold 5 model from: /content/drive/MyDrive/Stanford/CS229/Final Project/llama+udmp-densityclustering_synthetic cases/xgb_checkpoints/xgb_fold5_final.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "NUM_CLASS = len(le.classes_)  # already defined earlier\n",
        "\n",
        "for group_value, group_name in [(1, \"PubMed (case_group=1)\"),\n",
        "                                (2, \"Stanford (case_group=2)\")]:\n",
        "    mask = (df_ext[\"case_group\"] == group_value).values\n",
        "    if mask.sum() == 0:\n",
        "        print(f\"\\n⚠ No samples for group {group_value}, skipping.\")\n",
        "        continue\n",
        "\n",
        "    y_true_g = y_ext[mask]\n",
        "    y_proba_g = y_proba_ext[mask]\n",
        "\n",
        "    # labels must match the column order of y_proba_g\n",
        "    labels_all = np.arange(NUM_CLASS)\n",
        "\n",
        "    top1  = accuracy_score(y_true_g, np.argmax(y_proba_g, axis=1))\n",
        "    top10 = top_k_accuracy_score(y_true_g, y_proba_g, k=10, labels=labels_all)\n",
        "    top20 = top_k_accuracy_score(y_true_g, y_proba_g, k=20, labels=labels_all)\n",
        "\n",
        "    results[group_value] = {\n",
        "        \"top1\": top1,\n",
        "        \"top10\": top10,\n",
        "        \"top20\": top20,\n",
        "    }\n",
        "\n",
        "    print(f\"\\n=== {group_name} ===\")\n",
        "    print(f\"Samples: {mask.sum()}\")\n",
        "    print(f\"Top-1  accuracy: {top1:.4f}\")\n",
        "    print(f\"Top-10 accuracy: {top10:.4f}\")\n",
        "    print(f\"Top-20 accuracy: {top20:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2G3ydzRYJ32",
        "outputId": "695bb172-c27c-4c92-c89b-0ae4c80e74c0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== PubMed (case_group=1) ===\n",
            "Samples: 90\n",
            "Top-1  accuracy: 0.0222\n",
            "Top-10 accuracy: 0.0667\n",
            "Top-20 accuracy: 0.0889\n",
            "\n",
            "=== Stanford (case_group=2) ===\n",
            "Samples: 102\n",
            "Top-1  accuracy: 0.0196\n",
            "Top-10 accuracy: 0.1176\n",
            "Top-20 accuracy: 0.1765\n"
          ]
        }
      ]
    }
  ]
}